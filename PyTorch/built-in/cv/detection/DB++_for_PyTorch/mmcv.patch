diff --git a/mmcv/ops/modulated_deform_conv.py b/mmcv/ops/modulated_deform_conv.py
index df5095f..e90e20c 100644
--- a/mmcv/ops/modulated_deform_conv.py
+++ b/mmcv/ops/modulated_deform_conv.py
@@ -4,6 +4,7 @@ from typing import Optional, Tuple, Union
 
 import torch
 import torch.nn as nn
+from torch_npu.contrib.module.deform_conv import ModulatedDeformConv2dFunction
 from torch.autograd import Function
 from torch.autograd.function import once_differentiable
 from torch.nn.modules.utils import _pair, _single
@@ -16,146 +17,8 @@ ext_module = ext_loader.load_ext(
     '_ext',
     ['modulated_deform_conv_forward', 'modulated_deform_conv_backward'])
 
-
-class ModulatedDeformConv2dFunction(Function):
-
-    @staticmethod
-    def symbolic(g, input, offset, mask, weight, bias, stride, padding,
-                 dilation, groups, deform_groups):
-        input_tensors = [input, offset, mask, weight]
-        if bias is not None:
-            input_tensors.append(bias)
-        return g.op(
-            'mmcv::MMCVModulatedDeformConv2d',
-            *input_tensors,
-            stride_i=stride,
-            padding_i=padding,
-            dilation_i=dilation,
-            groups_i=groups,
-            deform_groups_i=deform_groups)
-
-    @staticmethod
-    def forward(ctx,
-                input: torch.Tensor,
-                offset: torch.Tensor,
-                mask: torch.Tensor,
-                weight: nn.Parameter,
-                bias: Optional[nn.Parameter] = None,
-                stride: int = 1,
-                padding: int = 0,
-                dilation: int = 1,
-                groups: int = 1,
-                deform_groups: int = 1) -> torch.Tensor:
-        if input is not None and input.dim() != 4:
-            raise ValueError(
-                f'Expected 4D tensor as input, got {input.dim()}D tensor \
-                  instead.')
-        ctx.stride = _pair(stride)
-        ctx.padding = _pair(padding)
-        ctx.dilation = _pair(dilation)
-        ctx.groups = groups
-        ctx.deform_groups = deform_groups
-        ctx.with_bias = bias is not None
-        if not ctx.with_bias:
-            bias = input.new_empty(0)  # fake tensor
-        # When pytorch version >= 1.6.0, amp is adopted for fp16 mode;
-        # amp won't cast the type of model (float32), but "offset" is cast
-        # to float16 by nn.Conv2d automatically, leading to the type
-        # mismatch with input (when it is float32) or weight.
-        # The flag for whether to use fp16 or amp is the type of "offset",
-        # we cast weight and input to temporarily support fp16 and amp
-        # whatever the pytorch version is.
-        input = input.type_as(offset)
-        weight = weight.type_as(input)
-        bias = bias.type_as(input)  # type: ignore
-        mask = mask.type_as(input)
-        ctx.save_for_backward(input, offset, mask, weight, bias)
-        output = input.new_empty(
-            ModulatedDeformConv2dFunction._output_size(ctx, input, weight))
-        ctx._bufs = [input.new_empty(0), input.new_empty(0)]
-        ext_module.modulated_deform_conv_forward(
-            input,
-            weight,
-            bias,
-            ctx._bufs[0],
-            offset,
-            mask,
-            output,
-            ctx._bufs[1],
-            kernel_h=weight.size(2),
-            kernel_w=weight.size(3),
-            stride_h=ctx.stride[0],
-            stride_w=ctx.stride[1],
-            pad_h=ctx.padding[0],
-            pad_w=ctx.padding[1],
-            dilation_h=ctx.dilation[0],
-            dilation_w=ctx.dilation[1],
-            group=ctx.groups,
-            deformable_group=ctx.deform_groups,
-            with_bias=ctx.with_bias)
-        return output
-
-    @staticmethod
-    @once_differentiable
-    def backward(ctx, grad_output: torch.Tensor) -> tuple:
-        input, offset, mask, weight, bias = ctx.saved_tensors
-        grad_input = torch.zeros_like(input)
-        grad_offset = torch.zeros_like(offset)
-        grad_mask = torch.zeros_like(mask)
-        grad_weight = torch.zeros_like(weight)
-        grad_bias = torch.zeros_like(bias)
-        grad_output = grad_output.contiguous()
-        ext_module.modulated_deform_conv_backward(
-            input,
-            weight,
-            bias,
-            ctx._bufs[0],
-            offset,
-            mask,
-            ctx._bufs[1],
-            grad_input,
-            grad_weight,
-            grad_bias,
-            grad_offset,
-            grad_mask,
-            grad_output,
-            kernel_h=weight.size(2),
-            kernel_w=weight.size(3),
-            stride_h=ctx.stride[0],
-            stride_w=ctx.stride[1],
-            pad_h=ctx.padding[0],
-            pad_w=ctx.padding[1],
-            dilation_h=ctx.dilation[0],
-            dilation_w=ctx.dilation[1],
-            group=ctx.groups,
-            deformable_group=ctx.deform_groups,
-            with_bias=ctx.with_bias)
-        if not ctx.with_bias:
-            grad_bias = None
-
-        return (grad_input, grad_offset, grad_mask, grad_weight, grad_bias,
-                None, None, None, None, None)
-
-    @staticmethod
-    def _output_size(ctx, input, weight):
-        channels = weight.size(0)
-        output_size = (input.size(0), channels)
-        for d in range(input.dim() - 2):
-            in_size = input.size(d + 2)
-            pad = ctx.padding[d]
-            kernel = ctx.dilation[d] * (weight.size(d + 2) - 1) + 1
-            stride_ = ctx.stride[d]
-            output_size += ((in_size + (2 * pad) - kernel) // stride_ + 1, )
-        if not all(map(lambda s: s > 0, output_size)):
-            raise ValueError(
-                'convolution input is too small (output would be ' +
-                'x'.join(map(str, output_size)) + ')')
-        return output_size
-
-
 modulated_deform_conv2d = ModulatedDeformConv2dFunction.apply
 
-
 class ModulatedDeformConv2d(nn.Module):
 
     @deprecated_api_warning({'deformable_groups': 'deform_groups'},
@@ -174,9 +37,9 @@ class ModulatedDeformConv2d(nn.Module):
         self.in_channels = in_channels
         self.out_channels = out_channels
         self.kernel_size = _pair(kernel_size)
-        self.stride = _pair(stride)
-        self.padding = _pair(padding)
-        self.dilation = _pair(dilation)
+        self.stride = stride #_pair(stride)
+        self.padding = padding #_pair(padding)
+        self.dilation = dilation #_pair(dilation)
         self.groups = groups
         self.deform_groups = deform_groups
         # enable compatibility with nn.Conv2d
@@ -190,6 +53,14 @@ class ModulatedDeformConv2d(nn.Module):
             self.bias = nn.Parameter(torch.Tensor(out_channels))
         else:
             self.register_parameter('bias', None)
+        self.split_num = self.deform_groups * 2 * self.kernel_size[0] * self.kernel_size[1]
+        sort_index_for_npu = list(range(self.split_num))
+        sort_index_for_npu_fp = sort_index_for_npu[1::2] + sort_index_for_npu[::2]
+        sort_index_for_npu_bp_dict = {i: idx for idx, i in enumerate(sort_index_for_npu_fp)}
+        sort_index_for_npu_bp = [sort_index_for_npu_bp_dict[i] for i in sort_index_for_npu]
+        self.sort_index_for_npu_fp = torch.IntTensor(sort_index_for_npu_fp)
+        self.sort_index_for_npu_bp = torch.IntTensor(sort_index_for_npu_bp)
+        self.sort_index_for_npu_todevice = False
         self.init_weights()
 
     def init_weights(self):
@@ -203,10 +74,18 @@ class ModulatedDeformConv2d(nn.Module):
 
     def forward(self, x: torch.Tensor, offset: torch.Tensor,
                 mask: torch.Tensor) -> torch.Tensor:
+
+        if not self.sort_index_for_npu_todevice:
+            self.sort_index_for_npu_fp = self.sort_index_for_npu_fp.to(x.device)
+            self.sort_index_for_npu_bp = self.sort_index_for_npu_bp.to(x.device)
+            self.bias = self.bias.to(x.device)
+            self.sort_index_for_npu_todevice = True
         return modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
-                                       self.stride, self.padding,
+                                       self.bias is not None, self.stride, self.padding,
                                        self.dilation, self.groups,
-                                       self.deform_groups)
+                                       self.deform_groups,
+                                       self.sort_index_for_npu_fp,
+                                       self.sort_index_for_npu_bp)
 
 
 @CONV_LAYERS.register_module('DCNv2')
@@ -252,10 +131,18 @@ class ModulatedDeformConv2dPack(ModulatedDeformConv2d):
         o1, o2, mask = torch.chunk(out, 3, dim=1)
         offset = torch.cat((o1, o2), dim=1)
         mask = torch.sigmoid(mask)
+        if not self.sort_index_for_npu_todevice:
+            self.sort_index_for_npu_fp = self.sort_index_for_npu_fp.to(x.device)
+            self.sort_index_for_npu_bp = self.sort_index_for_npu_bp.to(x.device)
+            if self.bias is not None:
+                self.bias = self.bias.to(x.device)
+            self.sort_index_for_npu_todevice = True
         return modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
-                                       self.stride, self.padding,
+                                       self.bias is not None, self.stride, self.padding,
                                        self.dilation, self.groups,
-                                       self.deform_groups)
+                                       self.deform_groups,
+                                       self.sort_index_for_npu_fp,
+                                       self.sort_index_for_npu_bp)
 
     def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,
                               missing_keys, unexpected_keys, error_msgs):
diff --git a/mmcv/runner/epoch_based_runner.py b/mmcv/runner/epoch_based_runner.py
index d6e9069..e3458c4 100644
--- a/mmcv/runner/epoch_based_runner.py
+++ b/mmcv/runner/epoch_based_runner.py
@@ -194,4 +194,4 @@ class Runner(EpochBasedRunner):
         warnings.warn(
             'Runner was deprecated, please use EpochBasedRunner instead',
             DeprecationWarning)
-        super().__init__(*args, **kwargs)
+        super().__init__(*args, **kwargs)
\ No newline at end of file
diff --git a/mmcv/runner/hooks/optimizer.py b/mmcv/runner/hooks/optimizer.py
index 9301547..6873800 100644
--- a/mmcv/runner/hooks/optimizer.py
+++ b/mmcv/runner/hooks/optimizer.py
@@ -14,6 +14,7 @@ from mmcv.utils import (IS_NPU_AVAILABLE, TORCH_VERSION, _BatchNorm,
 from ..dist_utils import allreduce_grads
 from ..fp16_utils import LossScaler, wrap_fp16_model
 from .hook import HOOKS, Hook
+from apex import amp
 
 try:
     # If PyTorch version >= 1.6.0, torch.cuda.amp.GradScaler would be imported
@@ -62,7 +63,8 @@ class OptimizerHook(Hook):
         runner.optimizer.zero_grad()
         if self.detect_anomalous_params:
             self.detect_anomalous_parameters(runner.outputs['loss'], runner)
-        runner.outputs['loss'].backward()
+        with amp.scale_loss(runner.outputs['loss'], runner.optimizer) as scaled_loss:
+            scaled_loss.backward()
 
         if self.grad_clip is not None:
             grad_norm = self.clip_grads(runner.model.parameters())
