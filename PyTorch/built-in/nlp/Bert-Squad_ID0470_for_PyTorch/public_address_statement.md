| 类型 | 开源代码地址 | 文件名 | 公网IP地址/公网URL地址/域名/邮箱地址 | 用途说明 |
| ---- | ------------ | ------ | ------------------------------------ | -------- |
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/triton/Dockerfile | Bert-Squad_ID0470_for_PyTorch/Dockerfile |https://github.com/attardi/wikiextractor.git|attardi_wikiextractor在开源社区上的git下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/triton/Dockerfile |Bert-Squad_ID0470_for_PyTorch/Dockerfile |https://github.com/soskek/bookcorpus.git|bookcorpus在开源社区上的git下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/requirements.txt |Bert-Squad_ID0470_for_PyTorch/Dockerfile |https://github.com/NVIDIA/dllogger|NVIDIA_dllogger在开源社区上的git下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/modeling.py |Bert-Squad_ID0470_for_PyTorch/modeling.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz|'bert-base-uncased'模型在开源社区上的bert-base-uncased.tar.gz的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/modeling.py |Bert-Squad_ID0470_for_PyTorch/modeling.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz|'bert-large-uncased'模型在开源社区上的bert-large-uncased.tar.gz的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/modeling.py |Bert-Squad_ID0470_for_PyTorch/modeling.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz|'bert-base-cased'模型在开源社区上的bert-base-cased.tar.gz的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/modeling.py |Bert-Squad_ID0470_for_PyTorch/modeling.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz|'bert-large-cased'模型在开源社区上的bert-large-cased.tar.gz的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/modeling.py |Bert-Squad_ID0470_for_PyTorch/modeling.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz|'bert-base-multilingual-uncased'模型在开源社区上的bert-base-multilingual-uncased.tar.gz的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/modeling.py |Bert-Squad_ID0470_for_PyTorch/modeling.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz|'bert-base-multilingual-cased'模型在开源社区上的bert-base-multilingual-cased.tar.gz的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/modeling.py|Bert-Squad_ID0470_for_PyTorch/modeling.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz|'bert-base-chinese'模型在开源社区上的bert-base-chinese.tar.gz的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py |Bert-Squad_ID0470_for_PyTorch/tokenization.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt|'bert-base-uncased'模型在开源社区上的bert-base-uncased-vocab.txt的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py |Bert-Squad_ID0470_for_PyTorch/tokenization.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt|'bert-large-uncased'模型在开源社区上的bert-large-uncased-vocab.txt的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py |Bert-Squad_ID0470_for_PyTorch/tokenization.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt|'bert-base-cased'模型在开源社区上的bert-base-cased-vocab.txt的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py |Bert-Squad_ID0470_for_PyTorch/tokenization.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt|'bert-large-cased'模型在开源社区上的bert-large-cased-vocab.txt的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py |Bert-Squad_ID0470_for_PyTorch/tokenization.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt|'bert-base-multilingual-uncased'模型在开源社区上的bert-base-multilingual-uncased-vocab.txt的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py |Bert-Squad_ID0470_for_PyTorch/tokenization.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt|'bert-base-multilingual-cased'模型在开源社区上的bert-base-multilingual-cased-vocab.txt的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py |Bert-Squad_ID0470_for_PyTorch/tokenization.py |https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt|'bert-base-chinese'模型在开源社区上的bert-base-chinese-vocab.txt的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/GooglePretrainedWeightDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/GooglePretrainedWeightDownloader.py |https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip |'bert_base_uncased'模型在开源社区上的uncased_L-12_H-768_A-12.zip下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/GooglePretrainedWeightDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/GooglePretrainedWeightDownloader.py |https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip |'bert_large_uncased'模型在开源社区上的uncased_L-24_H-1024_A-16.zip下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/GooglePretrainedWeightDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/GooglePretrainedWeightDownloader.py |https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip |'bert_base_cased'模型在开源社区上的cased_L-12_H-768_A-12.zip下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/GooglePretrainedWeightDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/GooglePretrainedWeightDownloader.py |https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip |'bert_large_cased'模型在开源社区上的cased_L-24_H-1024_A-16.zip下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/GooglePretrainedWeightDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/GooglePretrainedWeightDownloader.py |https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip |'bert_base_multilingual_cased'模型在开源社区上的multi_cased_L-12_H-768_A-12.zip下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/GooglePretrainedWeightDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/GooglePretrainedWeightDownloader.py |https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip |'bert_large_multilingual_uncased'模型在开源社区上的multilingual_L-12_H-768_A-12.zip下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/GooglePretrainedWeightDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/GooglePretrainedWeightDownloader.py |https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip |'bert_base_chinese'模型在开源社区上的chinese_L-12_H-768_A-12.zip下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/SquadDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/SquadDownloader.py |https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json |SQuAD模型在开源社区上的train-v1.1.json的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/SquadDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/SquadDownloader.py |https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json |SQuAD模型在开源社区上的dev-v1.1.json的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/SquadDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/SquadDownloader.py |https://worksheets.codalab.org/rest/bundles/0xbcd57bee090b421c982906709c8c27e1/contents/blob/|SQuAD模型在开源社区上的evaluate-v1.1.py的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/SquadDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/SquadDownloader.py |https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json |SQuAD模型在开源社区上的train-v2.0.json的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/SquadDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/SquadDownloader.py |https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json |SQuAD模型在开源社区上的dev-v2.0.json的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/SquadDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/SquadDownloader.py |https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/'|SQuAD模型在开源社区上的evaluate-v2.0.py的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/WikiDownloader.py | Bert-Squad_ID0470_for_PyTorch/data/WikiDownloader.py |https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2|enwiki在开源社区上的enwiki-latest-pages-articles.xml.bz2的下载链接|
| 开源代码引入 | https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/data/WikiDownloader.py |Bert-Squad_ID0470_for_PyTorch/data/WikiDownloader.py |https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2|zhwiki在开源社区上的zhwiki-latest-pages-articles.xml.bz的下载链接|
| 开源代码引入 | https://github.com/huggingface/transformers/blob/main/transformers/docs/source/en/main_classes/processors.mdx |Bert-Squad_ID0470_for_PyTorch/data/squad/squad_download.sh | https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json | SQuAD_train-v1.1在开源社区上的json下载链接|
| 开源代码引入 | https://github.com/huggingface/transformers/blob/main/transformers/docs/source/en/main_classes/processors.mdx |Bert-Squad_ID0470_for_PyTorch/data/squad/squad_download.sh | https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json | SQuAD_dev-v1.1在开源社区上的json下载链接|
| 开发引入 | / |Bert-Squad_ID0470_for_PyTorch/url.ini | https://worksheets.codalab.org/rest/bundles/0xbcd57bee090b421c982906709c8c27e1/contents |SQuAD_evaluate-v1.1在开源社区上的py下载链接|
| 开发引入 | / |Bert-Squad_ID0470_for_PyTorch/url.ini | https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents |SQuAD_evaluate-v2.0在开源社区上的py下载链接|
| 开源代码引入 | https://github.com/huggingface/transformers/blob/main/transformers/docs/source/en/main_classes/processors.mdx |Bert-Squad_ID0470_for_PyTorch/data/squad/squad_download.sh | https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json | SQuAD_train-v2.0在开源社区上的json下载链接|
| 开源代码引入 | https://github.com/huggingface/transformers/blob/main/transformers/docs/source/en/main_classes/processors.mdx |Bert-Squad_ID0470_for_PyTorch/data/squad/squad_download.sh | https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json | SQuAD_dev-v2.0在开源社区上的json下载链接|
| 开源代码引入 | https://github.com/huggingface/transformers/blob/main/transformers/docs/source/en/main_classes/processors.mdx |Bert-Squad_ID0470_for_PyTorch/data/squad/squad_download.sh | https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob |SQuAD_evaluate-v2.0在开源社区上的py下载链接|
| 开源代码引入 | https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/jukebox.mdx |Bert-Squad_ID0470_for_PyTorch/data/GLUEDownloader.py | https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py | SQuAD_download_glue_data在开源社区上的py下载链接|
| 开发引入 | / |Bert-Squad_ID0470_for_PyTorch/url.ini | https://github.com/rowanz/swagaf.git | SWAG在开源社区上的git下载链接|
