| 类型 | 开源代码地址 | 文件名 | 公网IP地址/公网URL地址/域名/邮箱地址 | 用途说明 |
| ---- | ------------ | ------ | ------------------------------------ | -------- |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/setup.py|roberta_for_PyTorch/setup.py	| https://stackoverflow.com/a/54128391 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/setup.py|roberta_for_PyTorch/setup.py	| https://download.pytorch.org/whl/cpu/torch-1.7.0%2Bcpu-cp36-cp36m-linux_x86_64.whl | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/setup.py|roberta_for_PyTorch/setup.py	| https://bit.ly/2NLVsgE | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/.github/ISSUE_TEMPLATE.md|roberta_for_PyTorch/setup.py	| https://github.com/pytorch/fairseq | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/data/audio/feature_transforms/specaugment.py|roberta_for_PyTorch/fairseq/data/audio/feature_transforms/specaugment.py	| https://arxiv.org/abs/1904.08779 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/modules/emformer.py|roberta_for_PyTorch/fairseq/models/speech_to_text/modules/emformer.py	| https://arxiv.org/abs/1803.02155 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/modules/augmented_memory_attention.py|roberta_for_PyTorch/fairseq/models/speech_to_text/modules/augmented_memory_attention.py	| https://arxiv.org/abs/2005.08042 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/modules/augmented_memory_attention.py|roberta_for_PyTorch/fairseq/models/speech_to_text/modules/augmented_memory_attention.py	| https://arxiv.org/abs/2005.09137 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/modules/emformer.py|roberta_for_PyTorch/fairseq/models/speech_to_text/modules/emformer.py	| https://arxiv.org/abs/2005.09684 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/README.md | roberta_for_PyTorch/docs/conf.py	| https://github.com/pytorch/fairseq/tree/master/docs/ | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/docs/conf.py|roberta_for_PyTorch/docs/conf.py	| http://docs.scipy.org/doc/numpy/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/docs/conf.py|roberta_for_PyTorch/docs/conf.py	| https://docs.python.org/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/docs/conf.py|roberta_for_PyTorch/docs/conf.py	| https://pytorch.org/docs/master/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/file_utils.py|roberta_for_PyTorch/fairseq/file_utils.py	| https://github.com/allenai/allennlp | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.md|roberta_for_PyTorch/fairseq/file_utils.py	| https://github.com/huggingface | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/layerdrop/README.md|roberta_for_PyTorch/fairseq/checkpoint_utils.py	| https://arxiv.org/abs/1909.11556 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/constrained_decoding/README.md|roberta_for_PyTorch/fairseq/search.py	| https://www.aclweb.org/anthology/N18-1119/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/constrained_decoding/README.md|roberta_for_PyTorch/fairseq/search.py	| https://www.aclweb.org/anthology/N19-1090/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/docs/make.bat|roberta_for_PyTorch/docs/make.bat	| http://sphinx-doc.org/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_dlm/sequence_generator/multichannel_search.py|roberta_for_PyTorch/fairseq/search.py	| https://arxiv.org/abs/1904.09751 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/search.py|roberta_for_PyTorch/fairseq/search.py	| https://arxiv.org/abs/1611.08562 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/unsupervised/w2vu_generate.py|roberta_for_PyTorch/fairseq_cli/hydra_train.py	| https://github.com/facebookresearch/hydra/issues/1126 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/unsupervised/w2vu_generate.py|roberta_for_PyTorch/fairseq_cli/train.py	| https://github.com/facebookresearch/hydra/issues/1126 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/scripts/build_sym_alignment.py|roberta_for_PyTorch/scripts/build_sym_alignment.py	| http://github.com/clab/fast_align | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/scripts/build_sym_alignment.py|roberta_for_PyTorch/scripts/build_sym_alignment.py	| http://github.com/moses-smt/mosesdecoder | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/scripts/build_sym_alignment.py|roberta_for_PyTorch/scripts/build_sym_alignment.py	| http://www.statmt.org/moses/?n=Development.GetStarted | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/multiprocessing_bpe_encoder.py	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json | 模型参数相关配置 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/multiprocessing_bpe_encoder.py	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/preprocess_GLUE_tasks.sh|roberta_for_PyTorch/examples/roberta/preprocess_GLUE_tasks.sh	| https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/preprocess_GLUE_tasks.sh	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json | 模型参数相关配置 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/preprocess_GLUE_tasks.sh	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/preprocess_GLUE_tasks.sh	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/preprocess_RACE.sh	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json | 模型参数相关配置 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/preprocess_RACE.sh	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/preprocess_RACE.sh	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/criterions/adaptive_loss.py|roberta_for_PyTorch/fairseq/criterions/adaptive_loss.py	| http://arxiv.org/abs/1609.04309 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/data/indexed_dataset.py|roberta_for_PyTorch/fairseq/data/indexed_dataset.py	| https://github.com/numpy/numpy/issues/5745 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/README.md|roberta_for_PyTorch/fairseq/data/mask_tokens_dataset.py	| https://arxiv.org/abs/1910.05453 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/dataclass/constants.py|roberta_for_PyTorch/fairseq/dataclass/constants.py	| https://github.com/facebookresearch/hydra/issues/1156 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/dataclass/configs.py|roberta_for_PyTorch/fairseq/dataclass/configs.py	| https://github.com/facebookresearch/hydra/issues/1117 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/fairseq_incremental_decoder.py|roberta_for_PyTorch/fairseq/models/fairseq_incremental_decoder.py	| http://www.telesens.co/2019/04/21/understanding-incremental-decoding-in-fairseq/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/conv_seq2seq/README.md|roberta_for_PyTorch/fairseq/models/fconv.py	| https://arxiv.org/abs/1705.03122 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/docs/getting_started.rst|roberta_for_PyTorch/fairseq/models/fconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt14.v2.en-fr.fconv-py.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/conv_seq2seq/README.md|roberta_for_PyTorch/fairseq/models/fconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-de.fconv-py.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/conv_seq2seq/README.md|roberta_for_PyTorch/fairseq/models/fconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt17.v2.en-de.fconv-py.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/fconv_self_att.py|roberta_for_PyTorch/fairseq/models/fconv_self_att.py	| https://dl.fbaipublicfiles.com/fairseq/models/stories_checkpoint.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/fconv_self_att.py|roberta_for_PyTorch/fairseq/models/fconv_self_att.py	| https://dl.fbaipublicfiles.com/fairseq/models/stories_checkpoint.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/stories/README.md|roberta_for_PyTorch/fairseq/models/fconv_self_att.py	| https://dl.fbaipublicfiles.com/fairseq/data/stories_test.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/lightconv.py|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://openreview.net/pdf?id=SkVhlh09tX | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/iwslt14.de-en.lightconv.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/iwslt14.de-en.dynamicconv.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.lightconv.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.dynamicconv.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.lightconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.dynamicconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.lightconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.dynamicconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt14.en-fr.joined-dict.lightconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt14.en-fr.joined-dict.dynamicconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt17.zh-en.lightconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pay_less_attention_paper/README.md|roberta_for_PyTorch/fairseq/models/lightconv.py	| https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt17.zh-en.dynamicconv-glu.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/language_model/README.adaptive_inputs.md|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_gbw_huge.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/language_model/README.adaptive_inputs.md|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_wiki103.v2.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer_lm.py|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.en.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer_lm.py|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.de.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer_lm.py|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.ru.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer_lm.py|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt20.en.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer_lm.py|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt20.ta.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer_lm.py|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt20.iu.news.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer_lm.py|roberta_for_PyTorch/fairseq/models/transformer_lm.py	| https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt20.iu.nh.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/criterions/adaptive_loss.py|roberta_for_PyTorch/fairseq/modules/adaptive_softmax.py	| http://arxiv.org/abs/1609.04309 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/modules/character_token_embedder.py|roberta_for_PyTorch/fairseq/modules/character_token_embedder.py	| https://arxiv.org/abs/1505.00387 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/nonautoregressive_translation/README.md|roberta_for_PyTorch/fairseq/modules/dynamic_crf_layer.py	| https://arxiv.org/abs/1910.11555 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/modules/dynamic_crf_layer.py|roberta_for_PyTorch/fairseq/modules/dynamic_crf_layer.py	| https://github.com/kmkurn/pytorch-crf/blob/master/torchcrf/__init__.py | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/modules/gelu.py|roberta_for_PyTorch/fairseq/modules/gelu.py	| https://github.com/hendrycks/GELUs | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/layerdrop/README.md|roberta_for_PyTorch/fairseq/modules/layer_drop.py	| https://arxiv.org/abs/1909.11556 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/modules/sparse_multihead_attention.py|roberta_for_PyTorch/fairseq/modules/sparse_multihead_attention.py	| https://arxiv.org/pdf/1904.10509.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/modules/vggblock.py|roberta_for_PyTorch/fairseq/modules/vggblock.py	| https://arxiv.org/pdf/1409.1556.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/adafactor.py|roberta_for_PyTorch/fairseq/optim/adafactor.py	| https://arxiv.org/abs/1804.04235 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/adam.py|roberta_for_PyTorch/fairseq/optim/adamax.py	| https://arxiv.org/abs/1412.6980 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/adam.py|roberta_for_PyTorch/fairseq/optim/adam.py	| https://arxiv.org/abs/1711.05101 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/adam.py|roberta_for_PyTorch/fairseq/optim/adam.py	| https://arxiv.org/abs/1412.6980 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/adam.py|roberta_for_PyTorch/fairseq/optim/adam.py	| https://openreview.net/forum?id=ryQu7f-RZ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/bmuf.py|roberta_for_PyTorch/fairseq/optim/bmuf.py	| https://ieeexplore.ieee.org/document/7472805 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/adam.py|roberta_for_PyTorch/fairseq/optim/fused_adam.py	| https://arxiv.org/abs/1412.6980 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/adam.py|roberta_for_PyTorch/fairseq/optim/fused_adam.py	| https://openreview.net/forum?id=ryQu7f-RZ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/scaling_nmt/README.md|roberta_for_PyTorch/fairseq/scoring/tokenizer.py	| https://github.com/mjpost/sacrebleu | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/cross_lingual_language_model/README.md|roberta_for_PyTorch/fairseq/tasks/cross_lingual_lm.py	| https://arxiv.org/pdf/1901.07291.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/tasks/fairseq_task.py|roberta_for_PyTorch/fairseq/tasks/fairseq_task.py	| https://arxiv.org/abs/2010.00904 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/tasks/fairseq_task.py|roberta_for_PyTorch/fairseq/tasks/fairseq_task.py	| https://github.com/facebookresearch/GENRE | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/nonautoregressive_translation/README.md|roberta_for_PyTorch/fairseq/tasks/translation_lev.py	| https://arxiv.org/abs/1905.11006 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/tasks/translation_lev.py|roberta_for_PyTorch/fairseq/tasks/translation_lev.py	| https://www.aclweb.org/anthology/2020.acl-main.325/ | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/commonsense_qa/download_cqa_data.sh|roberta_for_PyTorch/examples/roberta/commonsense_qa/download_cqa_data.sh	| https://s3.amazonaws.com/commensenseqa/train_rand_split.jsonl | 模型参数相关配置 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/commonsense_qa/download_cqa_data.sh|roberta_for_PyTorch/examples/roberta/commonsense_qa/download_cqa_data.sh	| https://s3.amazonaws.com/commensenseqa/dev_rand_split.jsonl | 模型参数相关配置 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/commonsense_qa/download_cqa_data.sh|roberta_for_PyTorch/examples/roberta/commonsense_qa/download_cqa_data.sh	| https://s3.amazonaws.com/commensenseqa/test_rand_split_no_answers.jsonl | 模型参数相关配置 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/examples/roberta/commonsense_qa/download_cqa_data.sh	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/clib/libbase/balanced_assignment.cpp|roberta_for_PyTorch/fairseq/clib/libbase/balanced_assignment.cpp	| https://dspace.mit.edu/bitstream/handle/1721.1/3265/P-2108-26912652.pdf | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/clib/libbase/balanced_assignment.cpp|roberta_for_PyTorch/fairseq/clib/libbase/balanced_assignment.cpp	| https://github.com/bkj/auction-lap | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/clib/libnat_cuda/binding.cpp|roberta_for_PyTorch/fairseq/clib/libnat_cuda/binding.cpp	| https://github.com/1ytic/pytorch-edit-distance | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/fairseq/data/encoders/gpt2_bpe.py	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json | 模型参数相关配置 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md|roberta_for_PyTorch/fairseq/data/encoders/gpt2_bpe.py	| https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/data/encoders/gpt2_bpe_utils.py|roberta_for_PyTorch/fairseq/data/encoders/gpt2_bpe_utils.py	| https://github.com/openai/gpt-2/blob/master/src/encoder.py | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/data/audio/speech_to_text_dataset.py|roberta_for_PyTorch/fairseq/data/audio/speech_to_text_dataset.py	| https://arxiv.org/abs/1907.05019 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/README.md | roberta_for_PyTorch/fairseq/models/bart/hub_interface.py	| https://github.com/pytorch/fairseq/tree/master/examples/bart | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/bart/model.py|roberta_for_PyTorch/fairseq/models/bart/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/bart.base.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/bart/model.py|roberta_for_PyTorch/fairseq/models/bart/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/bart/model.py|roberta_for_PyTorch/fairseq/models/bart/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/bart.large.mnli.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/bart/model.py|roberta_for_PyTorch/fairseq/models/bart/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/bart.large.cnn.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/bart/model.py|roberta_for_PyTorch/fairseq/models/bart/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/bart.large.xsum.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/README.md | roberta_for_PyTorch/fairseq/models/roberta/hub_interface.py	| https://github.com/pytorch/fairseq/tree/master/examples/roberta | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model.py|roberta_for_PyTorch/fairseq/models/roberta/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model.py|roberta_for_PyTorch/fairseq/models/roberta/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model.py|roberta_for_PyTorch/fairseq/models/roberta/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.mnli.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model.py|roberta_for_PyTorch/fairseq/models/roberta/model.py	| http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.wsc.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/hub_interface.py|roberta_for_PyTorch/fairseq/models/roberta/hub_interface.py	| https://github.com/pytorch/fairseq/issues/1306 | 模型相关说明 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-large.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-ccnet.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-ccnet-4gb.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-wikipedia-4gb.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_camembert.py|roberta_for_PyTorch/fairseq/models/roberta/model_camembert.py	| http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-oscar-4gb.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/gottbert/README.md|roberta_for_PyTorch/fairseq/models/roberta/model_gottbert.py	| https://dl.gottbert.de/fairseq/models/gottbert-base.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_xlmr.py|roberta_for_PyTorch/fairseq/models/roberta/model_xlmr.py	| http://dl.fbaipublicfiles.com/fairseq/models/xlmr.base.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_xlmr.py|roberta_for_PyTorch/fairseq/models/roberta/model_xlmr.py	| http://dl.fbaipublicfiles.com/fairseq/models/xlmr.large.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_xlmr.py|roberta_for_PyTorch/fairseq/models/roberta/model_xlmr.py	| http://dl.fbaipublicfiles.com/fairseq/models/xlmr/xlmr.xl.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/roberta/model_xlmr.py|roberta_for_PyTorch/fairseq/models/roberta/model_xlmr.py	| http://dl.fbaipublicfiles.com/fairseq/models/xlmr/xlmr.xxl.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://arxiv.org/abs/1802.04200 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://github.com/eske/seq2seq | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://github.com/eske/seq2seq/blob/master/config/LibriSpeech/AST.yaml | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://github.com/eske/seq2seq/blob/master/translate/models.py | 源码实现 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://arxiv.org/abs/1409.0473 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/convtransformer.py|roberta_for_PyTorch/fairseq/models/speech_to_text/convtransformer.py	| https://arxiv.org/abs/2004.10234 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/modules/convolution.py|roberta_for_PyTorch/fairseq/models/speech_to_text/s2t_transformer.py	| https://arxiv.org/abs/1911.08460 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pointer_generator/pointer_generator_src/transformer_pg.py|roberta_for_PyTorch/fairseq/models/speech_to_text/s2t_transformer.py	| https://arxiv.org/abs/1706.03762 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://arxiv.org/abs/1409.0473 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://arxiv.org/abs/1802.04200 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/speech_to_text/README.md|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://arxiv.org/abs/1909.06515 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/speech_to_text/berard.py|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://arxiv.org/pdf/2002.01320.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/speech_to_text/README.md|roberta_for_PyTorch/fairseq/models/speech_to_text/berard.py	| https://arxiv.org/abs/2006.12124 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/pointer_generator/pointer_generator_src/transformer_pg.py|roberta_for_PyTorch/fairseq/models/transformer/transformer_base.py	| https://arxiv.org/abs/1706.03762 | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/scaling_nmt/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/scaling_nmt/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2 | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/backtranslation/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt18.en-de.ensemble.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/translation/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.ensemble.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/translation/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.ensemble.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/translation/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.ensemble.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/translation/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.ensemble.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer/transformer_legacy.py|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer/transformer_legacy.py|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.single_model.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer/transformer_legacy.py|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.single_model.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer/transformer_legacy.py|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.single_model.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wmt20/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt20.en-ta.single.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wmt20/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt20.en-iu.news.single.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wmt20/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt20.en-iu.nh.single.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wmt20/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt20.ta-en.single.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wmt20/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt20.iu-en.news.single.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/wmt20/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/fairseq/models/wmt20.iu-en.nh.single.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/flores101/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/flores101/pretrained_models/flores101_mm100_615M.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/flores101/README.md|roberta_for_PyTorch/fairseq/models/transformer/transformer_legacy.py	| https://dl.fbaipublicfiles.com/flores101/pretrained_models/flores101_mm100_175M.tar.gz | 相应预训练模型 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/megatron_11b/README.md|roberta_for_PyTorch/fairseq/model_parallel/modules/multihead_attention.py	| https://arxiv.org/pdf/1909.08053.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/megatron_11b/README.md|roberta_for_PyTorch/fairseq/model_parallel/modules/transformer_layer.py	| https://arxiv.org/pdf/1909.08053.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/examples/megatron_11b/README.md|roberta_for_PyTorch/fairseq/model_parallel/modules/transformer_layer.py	| https://arxiv.org/pdf/1909.08053.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py|roberta_for_PyTorch/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py	| https://arxiv.org/pdf/1608.03983.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/lr_scheduler/triangular_lr_scheduler.py|roberta_for_PyTorch/fairseq/optim/lr_scheduler/triangular_lr_scheduler.py	| https://arxiv.org/pdf/1506.01186.pdf | 参考论文地址 |
| 开源代码引入 | https://github.com/facebookresearch/fairseq/blob/main/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py|roberta_for_PyTorch/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py	| https://arxiv.org/pdf/1904.08779.pdf | 参考论文地址 |