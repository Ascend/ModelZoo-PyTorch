# Copyright 2021 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#### general settings
name: train
use_tb_logger: true
model: SRFlow
distortion: sr
scale: 8
gpu_ids: [ 0 ]

#### datasets
datasets:
  train:
    name: CelebA_160_tr
    mode: LRHR_PKL
    dataroot_GT: ../datasets/celebA-train-gt.pklv4
    dataroot_LQ: ../datasets/celebA-train-x8.pklv4
    quant: 32

    use_shuffle: true
    n_workers: 3  # per GPU
    batch_size: 16
    GT_size: 160
    use_flip: true
    color: RGB
  val:
    name: CelebA_160_va
    mode: LRHR_PKL
    dataroot_GT: ../datasets/celebA-train-gt.pklv4
    dataroot_LQ: ../datasets/celebA-train-x8.pklv4
    quant: 32
    n_max: 20

#### Test Settings
dataroot_GT: ../datasets/celebA-validation-gt
dataroot_LR: ../datasets/celebA-validation-x8
model_path: ../pretrained_models/SRFlow_CelebA_8X.pth
heat: 0.9 # This is the standard deviation of the latent vectors

#### network structures
network_G:
  which_model_G: SRFlowNet
  in_nc: 3
  out_nc: 3
  nf: 64
  nb: 8
  upscale: 8
  train_RRDB: false
  train_RRDB_delay: 0.5

  flow:
    K: 16
    L: 4
    noInitialInj: true
    coupling: CondAffineSeparatedAndCond
    additionalFlowNoAffine: 2
    split:
      enable: true
    fea_up0: true
    stackRRDB:
      blocks: [ 1, 3, 5, 7 ]
      concat: true

#### path
path:
  pretrain_model_G: ../pretrained_models/RRDB_CelebA_8X.pth
  strict_load: true
  resume_state: auto

#### training settings: learning rate scheme, loss
train:
  manual_seed: 10
  lr_G: !!float 5e-4
  weight_decay_G: 0
  beta1: 0.9
  beta2: 0.99
  lr_scheme: MultiStepLR
  warmup_iter: -1  # no warm up
  lr_steps_rel: [ 0.5, 0.75, 0.9, 0.95 ]
  lr_gamma: 0.5

  niter: 200000
  val_freq: 40000

#### validation settings
val:
  heats: [ 0.0, 0.5, 0.75, 1.0 ]
  n_sample: 3

#### logger
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 1e3
