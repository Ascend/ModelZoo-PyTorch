{
  "name": "debug_001_adafmnet_noise75_DIV2K" // !!! please remove "debug_" during training
  , "use_tb_logger": true
  , "model":"sr"
  , "finetune_norm": true //finetune the adafm layers
  , "crop_size": 0
  , "gpu_ids": [0]

  , "datasets": {
    "train": {
      "name": "DIV2K"
      , "mode": "LRHR"
      , "dataroot_HR": "../datasets/DIV2K800/DIV2K800_sub"
      , "dataroot_LR": "../datasets/DIV2K800/DIV2K800_sub" // path for LR images
      , "subset_file": null
      , "use_shuffle": true
      , "n_workers": 8
      , "batch_size": 16
      , "HR_size": 96
      , "use_flip": true
      , "use_rot": true
    }
   , "val": {
      "name": "val_CBSD68"
      , "mode": "LRHR"
      , "dataroot_HR": "../datasets/val_CBSD68/CBSD68"
      , "dataroot_LR": "../datasets/val_CBSD68/CBSD68" // path for LR images
    }
  }

  , "path": {
    "root": "../" // root path
    // , "resume_state": "experiments/debug_001_adafmnet_noise75_DIV2K/training_state/200.state"
    , "pretrain_model_G": "../experiments/pretrained_models/noise15to75.pth" // the path for basic model
  }

  , "network_G": {
    "which_model_G": "adaptive_resnet"
    , "norm_type": "adafm" // basic | adafm | null | instance | batch
    , "nf": 64
    , "nb": 16
    , "in_nc": 3
    , "out_nc": 3
    , "adafm_ksize": 1 // the filter size of adafm during finetune. 1 | 3 | 5 | 7
  }

  , "train": {
    "lr_G": 1e-4
    , "lr_scheme": "MultiStepLR"
    , "lr_steps": [500000]
    , "lr_gamma": 0.1

    , "pixel_criterion": "l1"
    , "pixel_weight": 1.0
    , "val_freq": 5e3

    , "manual_seed": 0
    , "niter": 5e5 // the number of the whole training iterations
  }

  , "logger": {
    "print_freq": 200
    , "save_checkpoint_freq": 5e3
  }
}
