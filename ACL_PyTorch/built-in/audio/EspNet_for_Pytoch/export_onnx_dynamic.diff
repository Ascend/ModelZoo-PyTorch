diff --git a/espnet/asr/pytorch_backend/recog.py b/espnet/asr/pytorch_backend/recog.py
index 6c6d4ce11..73567f6c9 100644
--- a/espnet/asr/pytorch_backend/recog.py
+++ b/espnet/asr/pytorch_backend/recog.py
@@ -168,7 +168,21 @@ def recog_v2(args):
             logging.info("(%d/%d) decoding " + name, idx, len(js.keys()))
             batch = [(name, js[name])]
             feat = load_inputs_and_targets(batch)[0][0]
-            enc = model.encode(torch.as_tensor(feat).to(device=device, dtype=dtype))
+            #enc = model.encode(torch.as_tensor(feat).to(device=device, dtype=dtype))
+            input_tensor = torch.as_tensor(feat)
+
+            print("input_tensor.shape:", input_tensor.shape)
+            torch.onnx.export(model.encoder,
+                              (input_tensor),
+                              "encoder.onnx",
+                              input_names=['input'],
+                              dynamic_axes={'input': [0]},
+                              export_params=True,
+                              opset_version=11,
+                              do_constant_folding=True,
+                              verbose=True
+                              )
+            exit()
             nbest_hyps = beam_search(
                 x=enc, maxlenratio=args.maxlenratio, minlenratio=args.minlenratio
             )
diff --git a/espnet/nets/pytorch_backend/conformer/encoder.py b/espnet/nets/pytorch_backend/conformer/encoder.py
index 515cf7e3f..b0e86b0d5 100644
--- a/espnet/nets/pytorch_backend/conformer/encoder.py
+++ b/espnet/nets/pytorch_backend/conformer/encoder.py
@@ -237,7 +237,7 @@ class Encoder(torch.nn.Module):
                 conditioning_layer_dim, attention_dim
             )
 
-    def forward(self, xs, masks):
+    def forward(self, xs, masks=None):
         """Encode input sequence.
 
         Args:
@@ -249,6 +249,7 @@ class Encoder(torch.nn.Module):
             torch.Tensor: Mask tensor (#batch, time).
 
         """
+        xs = xs.unsqueeze(0)
         if isinstance(self.embed, (Conv2dSubsampling, VGG2L)):
             xs, masks = self.embed(xs, masks)
         else:
@@ -290,7 +291,8 @@ class Encoder(torch.nn.Module):
 
         if self.normalize_before:
             xs = self.after_norm(xs)
-
+        #
+        return xs
         if self.intermediate_layers is not None:
             return xs, masks, intermediate_outputs
         return xs, masks
