diff --git a/deep_sort/deep/feature_extractor.py b/deep_sort/deep/feature_extractor.py
index 0443e37..b5ecd6b 100644
--- a/deep_sort/deep/feature_extractor.py
+++ b/deep_sort/deep/feature_extractor.py
@@ -5,6 +5,8 @@ import cv2
 import logging
 
 from .model import Net
+from .acl_net_dynamic import NetDynamic
+
 
 class Extractor(object):
     def __init__(self, model_path, use_cuda=True):
@@ -20,7 +22,7 @@ class Extractor(object):
             transforms.ToTensor(),
             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
         ])
-        
+        self.model = NetDynamic(device_id=0, model_path="deep_dims.om")
 
 
     def _preprocess(self, im_crops):
@@ -43,8 +45,16 @@ class Extractor(object):
         im_batch = self._preprocess(im_crops)
         with torch.no_grad():
             im_batch = im_batch.to(self.device)
-            features = self.net(im_batch)
-        return features.cpu().numpy()
+            dynamic_dim = im_batch.shape[0]
+            dims = {'dimCount': 4, 'name': '', 'dims': [dynamic_dim, 3, 128, 64]}
+            im_batch = im_batch.cpu().numpy()
+            features = self.model([im_batch], dims)
+            # features = self.net(im_batch)
+            return features[0]
+        # return features.cpu().numpy()
+
+    def __del__(self):
+        del self.model
 
 
 if __name__ == '__main__':
diff --git a/detector/YOLOv3/detector.py b/detector/YOLOv3/detector.py
index 8fb302b..68c8694 100644
--- a/detector/YOLOv3/detector.py
+++ b/detector/YOLOv3/detector.py
@@ -6,6 +6,7 @@ import cv2
 from .darknet import Darknet
 from .yolo_utils import get_all_boxes, nms, post_process, xywh_to_xyxy, xyxy_to_xywh
 from .nms import boxes_nms
+from .acl_net_dynamic import NetDynamic
 
 
 class YOLOv3(object):
@@ -30,6 +31,12 @@ class YOLOv3(object):
         self.num_classes = self.net.num_classes
         self.class_names = self.load_class_names(namesfile)
 
+        self.dims = {'dimCount':4, 'name':'', 'dims':[1,3,416,416]}
+        self.model = NetDynamic(device_id = 0, model_path = "yolov3-sim.om")
+        self.anchors = [torch.tensor([3.625, 2.8125, 4.875, 6.1875, 11.65625, 10.1875]),
+                        torch.tensor([1.875, 3.8125, 3.875, 2.8125, 3.6875, 7.4375]),
+                        torch.tensor([1.25, 1.625, 2.0, 3.75, 4.125, 2.875])]
+
     def __call__(self, ori_img):
         # img to tensor
         assert isinstance(ori_img, np.ndarray), "input must be a numpy array!"
@@ -40,10 +47,15 @@ class YOLOv3(object):
 
         # forward
         with torch.no_grad():
-            img = img.to(self.device)
-            out_boxes = self.net(img)
-            boxes = get_all_boxes(out_boxes, self.conf_thresh, self.num_classes,
+            # img = img.to(self.device)
+            # out_boxes = self.net(img)
+
+            img = np.array(img, np.float32)
+            img = np.ascontiguousarray(img, dtype = np.float32)
+            out_boxes = self.model(img, self.dims)
+            boxes = get_all_boxes(out_boxes, self.anchors, self.conf_thresh, self.num_classes,
                                   use_cuda=self.use_cuda)  # batch size is 1
+
             # boxes = nms(boxes, self.nms_thresh)
 
             boxes = post_process(boxes, self.net.num_classes, self.conf_thresh, self.nms_thresh)[0].cpu()
diff --git a/detector/YOLOv3/yolo_utils.py b/detector/YOLOv3/yolo_utils.py
index b546eef..2296af1 100644
--- a/detector/YOLOv3/yolo_utils.py
+++ b/detector/YOLOv3/yolo_utils.py
@@ -158,14 +158,15 @@ def convert2cpu_long(gpu_matrix):
     return torch.LongTensor(gpu_matrix.size()).copy_(gpu_matrix)
 
 
-def get_all_boxes(output, conf_thresh, num_classes, only_objectness=1, validation=False, use_cuda=True):
+def get_all_boxes(output, output_anchors, conf_thresh, num_classes, only_objectness=1, validation=False, use_cuda=True):
     # total number of inputs (batch size)
     # first element (x) for first tuple (x, anchor_mask, num_anchor)
-    batchsize = output[0]['x'].data.size(0)
+    # batchsize = output[0]['x'].data.size(0)
 
     all_boxes = []
     for i in range(len(output)):
-        pred, anchors, num_anchors = output[i]['x'].data, output[i]['a'], output[i]['n'].item()
+        # pred, anchors, num_anchors = output[i]['x'].data, output[i]['a'], output[i]['n'].item()
+        pred, anchors, num_anchors = torch.from_numpy(output[i]), output_anchors[i], 3
         boxes = get_region_boxes(pred, conf_thresh, num_classes, anchors, num_anchors, \
                                  only_objectness=only_objectness, validation=validation, use_cuda=use_cuda)
 
