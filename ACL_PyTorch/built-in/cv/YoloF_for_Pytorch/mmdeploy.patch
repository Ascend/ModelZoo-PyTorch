diff --git a/mmdeploy/apis/pytorch2onnx.py b/mmdeploy/apis/pytorch2onnx.py
index e9912bc8..38165207 100644
--- a/mmdeploy/apis/pytorch2onnx.py
+++ b/mmdeploy/apis/pytorch2onnx.py
@@ -1,113 +1,127 @@
-# Copyright (c) OpenMMLab. All rights reserved.
-import os.path as osp
-from typing import Any, Optional, Tuple, Union
-
-import mmcv
-import torch
-
-from mmdeploy.core import RewriterContext, patch_model
-from mmdeploy.utils import (get_backend, get_dynamic_axes, get_input_shape,
-                            get_onnx_config, load_config)
-
-
-def torch2onnx_impl(model: torch.nn.Module, input: Union[torch.Tensor, Tuple],
-                    deploy_cfg: Union[str, mmcv.Config], output_file: str):
-    """Converting torch model to ONNX.
-
-    Args:
-        model (torch.nn.Module): Input pytorch model.
-        input (torch.Tensor | Tuple): Input tensor used to convert model.
-        deploy_cfg (str | mmcv.Config): Deployment config file or
-            Config object.
-        output_file (str): Output file to save ONNX model.
-    """
-    # load deploy_cfg if needed
-    deploy_cfg = load_config(deploy_cfg)[0]
-
-    onnx_cfg = get_onnx_config(deploy_cfg)
-    backend = get_backend(deploy_cfg).value
-    opset_version = onnx_cfg.get('opset_version', 11)
-
-    input_names = onnx_cfg['input_names']
-    output_names = onnx_cfg['output_names']
-    axis_names = input_names + output_names
-    dynamic_axes = get_dynamic_axes(deploy_cfg, axis_names)
-    verbose = not onnx_cfg.get('strip_doc_string', True) or onnx_cfg.get(
-        'verbose', False)
-
-    # patch model
-    patched_model = patch_model(model, cfg=deploy_cfg, backend=backend)
-
-    with RewriterContext(
-            cfg=deploy_cfg, backend=backend,
-            opset=opset_version), torch.no_grad():
-        torch.onnx.export(
-            patched_model,
-            input,
-            output_file,
-            export_params=onnx_cfg['export_params'],
-            input_names=input_names,
-            output_names=output_names,
-            opset_version=opset_version,
-            dynamic_axes=dynamic_axes,
-            keep_initializers_as_inputs=onnx_cfg[
-                'keep_initializers_as_inputs'],
-            verbose=verbose)
-
-
-def torch2onnx(img: Any,
-               work_dir: str,
-               save_file: str,
-               deploy_cfg: Union[str, mmcv.Config],
-               model_cfg: Union[str, mmcv.Config],
-               model_checkpoint: Optional[str] = None,
-               device: str = 'cuda:0'):
-    """Convert PyTorch model to ONNX model.
-
-    Examples:
-        >>> from mmdeploy.apis import torch2onnx
-        >>> img = 'demo.jpg'
-        >>> work_dir = 'work_dir'
-        >>> save_file = 'fcos.onnx'
-        >>> deploy_cfg = 'configs/mmdet/detection/' \
-            'detection_onnxruntime_dynamic.py'
-        >>> model_cfg = 'mmdetection/configs/fcos/' \
-            'fcos_r50_caffe_fpn_gn-head_1x_coco.py'
-        >>> model_checkpoint = 'checkpoints/' \
-            'fcos_r50_caffe_fpn_gn-head_1x_coco-821213aa.pth'
-        >>> device = 'cpu'
-        >>> torch2onnx(img, work_dir, save_file, deploy_cfg, \
-            model_cfg, model_checkpoint, device)
-
-    Args:
-        img (str | np.ndarray | torch.Tensor): Input image used to assist
-            converting model.
-        work_dir (str): A working directory to save files.
-        save_file (str): Filename to save onnx model.
-        deploy_cfg (str | mmcv.Config): Deployment config file or
-            Config object.
-        model_cfg (str | mmcv.Config): Model config file or Config object.
-        model_checkpoint (str): A checkpoint path of PyTorch model,
-            defaults to `None`.
-        device (str): A string specifying device type, defaults to 'cuda:0'.
-    """
-    # load deploy_cfg if necessary
-    deploy_cfg, model_cfg = load_config(deploy_cfg, model_cfg)
-    mmcv.mkdir_or_exist(osp.abspath(work_dir))
-    output_file = osp.join(work_dir, save_file)
-
-    input_shape = get_input_shape(deploy_cfg)
-
-    from mmdeploy.apis import build_task_processor
-    task_processor = build_task_processor(model_cfg, deploy_cfg, device)
-
-    torch_model = task_processor.init_pytorch_model(model_checkpoint)
-    data, model_inputs = task_processor.create_input(img, input_shape)
-    if not isinstance(model_inputs, torch.Tensor) and len(model_inputs) == 1:
-        model_inputs = model_inputs[0]
-
-    torch2onnx_impl(
-        torch_model,
-        model_inputs,
-        deploy_cfg=deploy_cfg,
-        output_file=output_file)
+# Copyright 2022 Huawei Technologies Co., Ltd
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import os.path as osp
+from typing import Any, Optional, Tuple, Union
+
+import mmcv
+import torch
+
+from mmdeploy.core import RewriterContext, patch_model
+from mmdeploy.utils import (get_backend, get_dynamic_axes, get_input_shape,
+                            get_onnx_config, load_config)
+
+
+def torch2onnx_impl(model: torch.nn.Module, input: Union[torch.Tensor, Tuple],
+                    deploy_cfg: Union[str, mmcv.Config], output_file: str):
+    """Converting torch model to ONNX.
+
+    Args:
+        model (torch.nn.Module): Input pytorch model.
+        input (torch.Tensor | Tuple): Input tensor used to convert model.
+        deploy_cfg (str | mmcv.Config): Deployment config file or
+            Config object.
+        output_file (str): Output file to save ONNX model.
+    """
+    # load deploy_cfg if needed
+    deploy_cfg = load_config(deploy_cfg)[0]
+
+    onnx_cfg = get_onnx_config(deploy_cfg)
+    backend = get_backend(deploy_cfg).value
+    opset_version = onnx_cfg.get('opset_version', 11)
+
+    input_names = onnx_cfg['input_names']
+    output_names = onnx_cfg['output_names']
+    axis_names = input_names + output_names
+    dynamic_axes = get_dynamic_axes(deploy_cfg, axis_names)
+    verbose = not onnx_cfg.get('strip_doc_string', True) or onnx_cfg.get(
+        'verbose', False)
+
+    # patch model
+    patched_model = patch_model(model, cfg=deploy_cfg, backend=backend)
+
+    with RewriterContext(
+            cfg=deploy_cfg, backend=backend,
+            opset=opset_version), torch.no_grad():
+        torch.onnx.export(
+            patched_model,
+            input,
+            output_file,
+            export_params=onnx_cfg['export_params'],
+            input_names=input_names,
+            output_names=output_names,
+            opset_version=opset_version,
+            dynamic_axes=dynamic_axes,
+            enable_onnx_checker=False,
+            keep_initializers_as_inputs=onnx_cfg[
+                'keep_initializers_as_inputs'],
+            verbose=verbose)
+
+
+def torch2onnx(img: Any,
+               work_dir: str,
+               save_file: str,
+               deploy_cfg: Union[str, mmcv.Config],
+               model_cfg: Union[str, mmcv.Config],
+               model_checkpoint: Optional[str] = None,
+               device: str = 'cuda:0'):
+    """Convert PyTorch model to ONNX model.
+
+    Examples:
+        >>> from mmdeploy.apis import torch2onnx
+        >>> img = 'demo.jpg'
+        >>> work_dir = 'work_dir'
+        >>> save_file = 'fcos.onnx'
+        >>> deploy_cfg = 'configs/mmdet/detection/' \
+            'detection_onnxruntime_dynamic.py'
+        >>> model_cfg = 'mmdetection/configs/fcos/' \
+            'fcos_r50_caffe_fpn_gn-head_1x_coco.py'
+        >>> model_checkpoint = 'checkpoints/' \
+            'fcos_r50_caffe_fpn_gn-head_1x_coco-821213aa.pth'
+        >>> device = 'cpu'
+        >>> torch2onnx(img, work_dir, save_file, deploy_cfg, \
+            model_cfg, model_checkpoint, device)
+
+    Args:
+        img (str | np.ndarray | torch.Tensor): Input image used to assist
+            converting model.
+        work_dir (str): A working directory to save files.
+        save_file (str): Filename to save onnx model.
+        deploy_cfg (str | mmcv.Config): Deployment config file or
+            Config object.
+        model_cfg (str | mmcv.Config): Model config file or Config object.
+        model_checkpoint (str): A checkpoint path of PyTorch model,
+            defaults to `None`.
+        device (str): A string specifying device type, defaults to 'cuda:0'.
+    """
+    # load deploy_cfg if necessary
+    deploy_cfg, model_cfg = load_config(deploy_cfg, model_cfg)
+    mmcv.mkdir_or_exist(osp.abspath(work_dir))
+    output_file = osp.join(work_dir, save_file)
+
+    input_shape = get_input_shape(deploy_cfg)
+
+    from mmdeploy.apis import build_task_processor
+    task_processor = build_task_processor(model_cfg, deploy_cfg, device)
+
+    torch_model = task_processor.init_pytorch_model(model_checkpoint)
+    data, model_inputs = task_processor.create_input(img, input_shape)
+    if not isinstance(model_inputs, torch.Tensor) and len(model_inputs) == 1:
+        model_inputs = model_inputs[0]
+
+    torch2onnx_impl(
+        torch_model,
+        model_inputs,
+        deploy_cfg=deploy_cfg,
+        output_file=output_file)
diff --git a/mmdeploy/codebase/mmdet/core/post_processing/bbox_nms.py b/mmdeploy/codebase/mmdet/core/post_processing/bbox_nms.py
index ee7a1403..481ae42d 100644
--- a/mmdeploy/codebase/mmdet/core/post_processing/bbox_nms.py
+++ b/mmdeploy/codebase/mmdet/core/post_processing/bbox_nms.py
@@ -1,4 +1,17 @@
-# Copyright (c) OpenMMLab. All rights reserved.
+# Copyright 2022 Huawei Technologies Co., Ltd
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import torch
 from torch import Tensor
 
@@ -7,6 +20,56 @@ from mmdeploy.core import FUNCTION_REWRITER, mark
 from mmdeploy.mmcv.ops import ONNXNMSop, TRTBatchedNMSop
 from mmdeploy.utils import Backend, is_dynamic_batch
 
+class BatchNMSOp(torch.autograd.Function):
+    @staticmethod
+    def forward(ctx, bboxes, scores, score_threshold, iou_threshold, max_size_per_class, max_total_size, image_size):
+        """
+        boxes (torch.Tensor): boxes in shape (batch, N, C, 4).
+        scores (torch.Tensor): scores in shape (batch, N, C).
+        return:
+            nmsed_boxes: (1, N, 4)
+            nmsed_scores: (1, N)
+            nmsed_classes: (1, N)
+            nmsed_num: (1,)
+        """
+
+        # Phony implementation for onnx export
+        nmsed_boxes = bboxes[:, :max_total_size, 0, :]
+        nmsed_scores = torch.rand(1, max_total_size)
+        nmsed_classes = torch.arange(max_total_size * bboxes.shape[0], dtype=torch.long)
+        nmsed_num = torch.Tensor([max_total_size])
+
+        return nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num
+
+    @staticmethod
+    def symbolic(g, bboxes, scores, score_thr, iou_thr, max_size_p_class, max_t_size, image_size):
+        nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num = g.op('BatchMultiClassNMS',
+            bboxes, scores, score_threshold_f=score_thr, iou_threshold_f=iou_thr,
+            max_size_per_class_i=max_size_p_class, max_total_size_i=max_t_size, image_size_i=image_size, outputs=4)
+        return nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num
+
+def batch_nms_op(bboxes, scores, score_threshold, iou_threshold, max_size_per_class, max_total_size, image_size):
+    """
+    boxes (torch.Tensor): boxes in shape (N, 4).
+    scores (torch.Tensor): scores in shape (N, ).
+    """
+
+    if bboxes.dtype == torch.float32:
+        bboxes = bboxes.reshape(bboxes.shape[0], bboxes.shape[1], -1, 4).half()
+        scores = scores.reshape(scores.shape[0], scores.shape[1], -1).half()
+    else:
+        bboxes = bboxes.reshape(bboxes.shape[0], bboxes.shape[1], -1, 4)
+        scores = scores.reshape(scores.shape[0], scores.shape[1], -1)
+
+    nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num = BatchNMSOp.apply(bboxes, scores,
+        score_threshold, iou_threshold, max_size_per_class, max_total_size, image_size)
+    nmsed_boxes = nmsed_boxes.float()
+    nmsed_scores = nmsed_scores.float()
+    nmsed_classes = nmsed_classes.long()
+    dets = torch.cat((nmsed_boxes.reshape((-1, max_total_size, 4)), nmsed_scores.reshape((-1, max_total_size, 1))), -1)
+    labels = nmsed_classes.reshape((-1, max_total_size))
+    labels = labels.int()
+    return dets, labels
 
 def select_nms_index(scores: torch.Tensor,
                      boxes: torch.Tensor,
@@ -14,7 +77,6 @@ def select_nms_index(scores: torch.Tensor,
                      batch_size: int,
                      keep_top_k: int = -1):
     """Transform NMS output.
-
     Args:
         scores (Tensor): The detection scores of shape
             [N, num_classes, num_boxes].
@@ -23,7 +85,6 @@ def select_nms_index(scores: torch.Tensor,
         batch_size (int): Batch size of the input image.
         keep_top_k (int): Number of top K boxes to keep after nms.
             Defaults to -1.
-
     Returns:
         tuple[Tensor, Tensor]: (dets, labels), `dets` of shape [N, num_det, 5]
             and `labels` of shape [N, num_det].
@@ -59,7 +120,7 @@ def select_nms_index(scores: torch.Tensor,
 
     # sort
     is_use_topk = keep_top_k > 0 and \
-        (torch.onnx.is_in_onnx_export() or keep_top_k < batched_dets.shape[1])
+                  (torch.onnx.is_in_onnx_export() or keep_top_k < batched_dets.shape[1])
     if is_use_topk:
         _, topk_inds = batched_dets[:, :, -1].topk(keep_top_k, dim=1)
     else:
@@ -82,7 +143,6 @@ def _multiclass_nms(boxes: Tensor,
                     pre_top_k: int = -1,
                     keep_top_k: int = -1):
     """Create a dummy onnx::NonMaxSuppression op while exporting to ONNX.
-
     This function helps exporting to onnx with batch and multiclass NMS op. It
     only supports class-agnostic detection results. That is, the scores is of
     shape (N, num_bboxes, num_classes) and the boxes is of shape (N, num_boxes,
@@ -92,7 +152,7 @@ def _multiclass_nms(boxes: Tensor,
     iou_threshold = torch.tensor([iou_threshold], dtype=torch.float32)
     score_threshold = torch.tensor([score_threshold], dtype=torch.float32)
     batch_size = scores.shape[0]
-
+    pre_top_k = 512
     if pre_top_k > 0:
         max_scores, _ = scores.max(-1)
         _, topk_inds = max_scores.topk(pre_top_k)
@@ -101,14 +161,9 @@ def _multiclass_nms(boxes: Tensor,
         boxes = boxes[batch_inds, topk_inds, :]
         scores = scores[batch_inds, topk_inds, :]
 
-    scores = scores.permute(0, 2, 1)
-    selected_indices = ONNXNMSop.apply(boxes, scores,
-                                       max_output_boxes_per_class,
-                                       iou_threshold, score_threshold)
-
-    dets, labels = select_nms_index(
-        scores, boxes, selected_indices, batch_size, keep_top_k=keep_top_k)
-
+    #scores = scores.permute(0, 2, 1)
+    dets, labels = batch_nms_op(boxes, scores, score_threshold.item(), iou_threshold.item(),
+                                256, 96, (2048, 2048))
     return dets, labels
 
 
@@ -120,7 +175,6 @@ def _multiclass_nms_single(boxes: Tensor,
                            pre_top_k: int = -1,
                            keep_top_k: int = -1):
     """Create a dummy onnx::NonMaxSuppression op while exporting to ONNX.
-
     Single batch nms could be optimized.
     """
     max_output_boxes_per_class = torch.LongTensor([max_output_boxes_per_class])
@@ -153,7 +207,7 @@ def _multiclass_nms_single(boxes: Tensor,
 
     # topk or sort
     is_use_topk = keep_top_k > 0 and \
-        (torch.onnx.is_in_onnx_export() or keep_top_k < dets.shape[1])
+                  (torch.onnx.is_in_onnx_export() or keep_top_k < dets.shape[1])
     if is_use_topk:
         _, topk_inds = dets[:, :, -1].topk(keep_top_k, dim=1)
     else:
@@ -176,12 +230,10 @@ def multiclass_nms__default(ctx,
                             pre_top_k: int = -1,
                             keep_top_k: int = -1):
     """Create a dummy onnx::NonMaxSuppression op while exporting to ONNX.
-
     This function helps exporting to onnx with batch and multiclass NMS op.
     It only supports class-agnostic detection results. That is, the scores
     is of shape (N, num_bboxes, num_classes) and the boxes is of shape
     (N, num_boxes, 4).
-
     Args:
         boxes (Tensor): The bounding boxes of shape [N, num_boxes, 4].
         scores (Tensor): The detection scores of shape
@@ -195,14 +247,13 @@ def multiclass_nms__default(ctx,
             Defaults to -1.
         keep_top_k (int): Number of top K boxes to keep after nms.
             Defaults to -1.
-
     Returns:
         tuple[Tensor, Tensor]: (dets, labels), `dets` of shape [N, num_det, 5]
             and `labels` of shape [N, num_det].
     """
     deploy_cfg = ctx.cfg
     batch_size = boxes.size(0)
-    if not is_dynamic_batch(deploy_cfg) and batch_size != 1:
+    if not is_dynamic_batch(deploy_cfg) and batch_size == 1:
         return _multiclass_nms_single(
             boxes,
             scores,
@@ -234,7 +285,6 @@ def multiclass_nms_static(ctx,
                           pre_top_k: int = -1,
                           keep_top_k: int = -1):
     """Wrapper for `multiclass_nms` with TensorRT.
-
     Args:
         ctx (ContextCaller): The context with additional information.
         boxes (Tensor): The bounding boxes of shape [N, num_boxes, 4].
@@ -249,7 +299,6 @@ def multiclass_nms_static(ctx,
             Defaults to -1.
         keep_top_k (int): Number of top K boxes to keep after nms.
             Defaults to -1.
-
     Returns:
         tuple[Tensor, Tensor]: (dets, labels), `dets` of shape [N, num_det, 5]
             and `labels` of shape [N, num_det].
@@ -283,7 +332,6 @@ def multiclass_nms__torchscript(ctx,
                                 pre_top_k: int = -1,
                                 keep_top_k: int = -1):
     """rewrite for torchscript batched nms.
-
     Use batched_nms from torchvision instead of custom nms.
     """
     # TODO: simplify inference for non-batch model
diff --git a/tools/deploy.py b/tools/deploy.py
index 330c7c2f..5ab4479d 100644
--- a/tools/deploy.py
+++ b/tools/deploy.py
@@ -1,4 +1,17 @@
-# Copyright (c) OpenMMLab. All rights reserved.
+# Copyright 2022 Huawei Technologies Co., Ltd
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import argparse
 import logging
 import os.path as osp
@@ -268,13 +281,7 @@ def main():
     if args.test_img is None:
         args.test_img = args.img
 
-    headless = False
-    # check headless or not for all platforms.
-    import tkinter
-    try:
-        tkinter.Tk()
-    except Exception:
-        headless = True
+    headless = True
 
     # for headless installation.
     if not headless:
