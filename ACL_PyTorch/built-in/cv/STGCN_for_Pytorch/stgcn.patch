diff -Naru a/mmskeleton/models/backbones/st_gcn_aaai18.py b/mmskeleton/models/backbones/st_gcn_aaai18.py
--- a/mmskeleton/models/backbones/st_gcn_aaai18.py	2022-12-15 10:31:29.588727702 +0000
+++ b/mmskeleton/models/backbones/st_gcn_aaai18.py	2022-12-15 10:36:45.532731573 +0000
@@ -101,7 +101,9 @@
             x, _ = gcn(x, self.A * importance)
 
         # global pooling
-        x = F.avg_pool2d(x, x.size()[2:])
+        # x = F.avg_pool2d(x, x.size()[2:])
+        assert x.size(2) == 75 and x.size(3) == 18, str(x.size())
+        x = F.avg_pool2d(x, (75, 18))
         x = x.view(N, M, -1, 1, 1).mean(dim=1)
 
         # prediction
diff -Naru a/mmskeleton/ops/st_gcn/gconv.py b/mmskeleton/ops/st_gcn/gconv.py
--- a/mmskeleton/ops/st_gcn/gconv.py	2022-12-15 10:31:29.592727702 +0000
+++ b/mmskeleton/ops/st_gcn/gconv.py	2022-12-15 10:35:27.172730613 +0000
@@ -4,6 +4,17 @@
 import torch.nn as nn
 
 
+def forge_einsum(x, A):
+    x = x.permute(0, 2, 3, 1, 4).contiguous()
+    n, c, t, k, v = x.size()
+    k, v, w = A.size()
+    x = x.view(n * c * t, k * v)
+    A = A.view(k * v, w)
+    x = torch.matmul(x, A)
+    x = x.view(n, c, t, w)
+    return x
+
+
 class GraphConvND(nn.Module):
     def __init__(self, N, in_channels, out_channels, kernel_size, stride,
                  padding, dilation, groups, bias, padding_mode):
@@ -54,7 +65,8 @@
         x = self.conv(x)
         x = x.view((x.size(0), self.graph_kernel_size, self.out_channels) +
                    x.size()[2:])
-        x = torch.einsum(self.einsum_func, (x, A))
+        # x = torch.einsum(self.einsum_func, (x, A))
+        x = forge_einsum(x, A)
 
         return x.contiguous(), out_graph
 
diff -Naru a/mmskeleton/ops/st_gcn/gconv_origin.py b/mmskeleton/ops/st_gcn/gconv_origin.py
--- a/mmskeleton/ops/st_gcn/gconv_origin.py	2022-12-15 10:31:29.592727702 +0000
+++ b/mmskeleton/ops/st_gcn/gconv_origin.py	2022-12-15 10:34:53.656730203 +0000
@@ -5,6 +5,17 @@
 import torch.nn as nn
 
 
+def forge_einsum(x, A):
+    x = x.permute(0, 2, 3, 1, 4).contiguous()
+    n, c, t, k, v = x.size()
+    k, v, w = A.size()
+    x = x.view(n * c * t, k * v)
+    A = A.view(k * v, w)
+    x = torch.matmul(x, A)
+    x = x.view(n, c, t, w)
+    return x
+
+
 class ConvTemporalGraphical(nn.Module):
     r"""The basic module for applying a graph convolution.
 
@@ -60,7 +71,8 @@
 
         n, kc, t, v = x.size()
         x = x.view(n, self.kernel_size, kc // self.kernel_size, t, v)
-        x = torch.einsum('nkctv,kvw->nctw', (x, A))
+        # x = torch.einsum('nkctv,kvw->nctw', (x, A))
+        x = forge_einsum(x, A)
 
         return x.contiguous(), A
 
