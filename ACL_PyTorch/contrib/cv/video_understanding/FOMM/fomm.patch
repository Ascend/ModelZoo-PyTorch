---
 config/taichi-256.yaml  |  2 +-
 logger.py               |  7 ++--
 modules/dense_motion.py |  6 ++--
 modules/generator.py    |  5 +--
 reconstruction.py       | 79 ++++++++++++++++++++++++++++++++++-------
 5 files changed, 77 insertions(+), 22 deletions(-)

diff --git a/config/taichi-256.yaml b/config/taichi-256.yaml
index 44b7839..332a7fb 100644
--- a/config/taichi-256.yaml
+++ b/config/taichi-256.yaml
@@ -9,7 +9,7 @@
 # video id.
 dataset_params:
   # Path to data, data can be stored in several formats: .mp4 or .gif videos, stacked .png images or folders with frames.
-  root_dir: data/taichi-png
+  root_dir: data/taichi
   # Image shape, needed for staked .png format.
   frame_shape: [256, 256, 3]
   # In case of TaiChi single video can be splitted in many chunks, or the maybe several videos for single person.
diff --git a/logger.py b/logger.py
index f6d14b0..ef20860 100644
--- a/logger.py
+++ b/logger.py
@@ -50,11 +50,7 @@ class Logger:
     @staticmethod
     def load_cpk(checkpoint_path, generator=None, discriminator=None, kp_detector=None,
                  optimizer_generator=None, optimizer_discriminator=None, optimizer_kp_detector=None):
-        if torch.cuda.is_available():
-            map_location = None
-        else:
-            map_location = 'cpu'
-        checkpoint = torch.load(checkpoint_path, map_location)
+        checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))
         if generator is not None:
             generator.load_state_dict(checkpoint['generator'])
         if kp_detector is not None:
@@ -123,6 +119,7 @@ class Visualizer:
         if self.draw_border:
             images = np.copy(images)
             images[:, :, [0, -1]] = (1, 1, 1)
+            images[:, :, [0, -1]] = (1, 1, 1)
         return np.concatenate(list(images), axis=0)
 
     def create_image_grid(self, *args):
diff --git a/modules/dense_motion.py b/modules/dense_motion.py
index 06f7039..e08864d 100644
--- a/modules/dense_motion.py
+++ b/modules/dense_motion.py
@@ -2,6 +2,8 @@ from torch import nn
 import torch.nn.functional as F
 import torch
 from modules.util import Hourglass, AntiAliasInterpolation2d, make_coordinate_grid, kp2gaussian
+from point_grid_my import bilinear_grid_sample
+from inverse_without_cat import invmat
 
 
 class DenseMotionNetwork(nn.Module):
@@ -53,7 +55,7 @@ class DenseMotionNetwork(nn.Module):
         identity_grid = identity_grid.view(1, 1, h, w, 2)
         coordinate_grid = identity_grid - kp_driving['value'].view(bs, self.num_kp, 1, 1, 2)
         if 'jacobian' in kp_driving:
-            jacobian = torch.matmul(kp_source['jacobian'], torch.inverse(kp_driving['jacobian']))
+            jacobian = torch.matmul(kp_source['jacobian'], invmat(kp_driving['jacobian']))
             jacobian = jacobian.unsqueeze(-3).unsqueeze(-3)
             jacobian = jacobian.repeat(1, 1, h, w, 1, 1)
             coordinate_grid = torch.matmul(jacobian, coordinate_grid.unsqueeze(-1))
@@ -74,7 +76,7 @@ class DenseMotionNetwork(nn.Module):
         source_repeat = source_image.unsqueeze(1).unsqueeze(1).repeat(1, self.num_kp + 1, 1, 1, 1, 1)
         source_repeat = source_repeat.view(bs * (self.num_kp + 1), -1, h, w)
         sparse_motions = sparse_motions.view((bs * (self.num_kp + 1), h, w, -1))
-        sparse_deformed = F.grid_sample(source_repeat, sparse_motions)
+        sparse_deformed = bilinear_grid_sample(source_repeat, sparse_motions)
         sparse_deformed = sparse_deformed.view((bs, self.num_kp + 1, -1, h, w))
         return sparse_deformed
 
diff --git a/modules/generator.py b/modules/generator.py
index ec66570..8393141 100644
--- a/modules/generator.py
+++ b/modules/generator.py
@@ -3,6 +3,7 @@ from torch import nn
 import torch.nn.functional as F
 from modules.util import ResBlock2d, SameBlock2d, UpBlock2d, DownBlock2d
 from modules.dense_motion import DenseMotionNetwork
+from point_grid_my import bilinear_grid_sample
 
 
 class OcclusionAwareGenerator(nn.Module):
@@ -54,7 +55,7 @@ class OcclusionAwareGenerator(nn.Module):
             deformation = deformation.permute(0, 3, 1, 2)
             deformation = F.interpolate(deformation, size=(h, w), mode='bilinear')
             deformation = deformation.permute(0, 2, 3, 1)
-        return F.grid_sample(inp, deformation)
+        return bilinear_grid_sample(inp, deformation, align_corners=True)
 
     def forward(self, source_image, kp_driving, kp_source):
         # Encoding (downsampling) part
@@ -80,7 +81,7 @@ class OcclusionAwareGenerator(nn.Module):
 
             if occlusion_map is not None:
                 if out.shape[2] != occlusion_map.shape[2] or out.shape[3] != occlusion_map.shape[3]:
-                    occlusion_map = F.interpolate(occlusion_map, size=out.shape[2:], mode='bilinear')
+                    occlusion_map = F.interpolate(occlusion_map, size=out.shape[2:], mode='bilinear', align_corners=True)
                 out = out * occlusion_map
 
             output_dict["deformed"] = self.deform_input(source_image, deformation)
diff --git a/reconstruction.py b/reconstruction.py
index cb211df..fdc1718 100644
--- a/reconstruction.py
+++ b/reconstruction.py
@@ -8,7 +8,7 @@ import imageio
 from sync_batchnorm import DataParallelWithCallback
 
 
-def reconstruction(config, generator, kp_detector, checkpoint, log_dir, dataset):
+def reconstruction(config, generator, kp_detector, checkpoint, log_dir, dataset, data_dir="infer_out/", pre_data="pre_data/"):
     png_dir = os.path.join(log_dir, 'reconstruction/png')
     log_dir = os.path.join(log_dir, 'reconstruction')
 
@@ -32,28 +32,83 @@ def reconstruction(config, generator, kp_detector, checkpoint, log_dir, dataset)
     generator.eval()
     kp_detector.eval()
 
+    if not data_dir.__contains__('/'):
+        data_dir += "/"
+
+    if not pre_data.__contains__('/'):
+        pre_data += "/"
+    kpdv_path = data_dir + "kpdv/"
+    kpdj_path = data_dir + "kpdj/"
+    kpsv_path = data_dir + "kpsv/"
+    kpsj_path = data_dir + "kpsj/"
+    source_path = pre_data + "source/"
+    driving_path = pre_data + "driving/"
+    out_path = data_dir + "out/"
+
+    cnt = 0
+
     for it, x in tqdm(enumerate(dataloader)):
         if config['reconstruction_params']['num_videos'] is not None:
             if it > config['reconstruction_params']['num_videos']:
                 break
+        num = x['video'].shape[2]
+        del x['video']
+        file_num_file = np.load(pre_data + "frame_num.npy")
+        file_num = file_num_file[it]
+        if num != file_num:
+            raise ValueError("{}:file num != num, num is {}, but file num is {}".format(it, num, file_num))
         with torch.no_grad():
             predictions = []
             visualizations = []
-            if torch.cuda.is_available():
-                x['video'] = x['video'].cuda()
-            kp_source = kp_detector(x['video'][:, :, 0])
-            for frame_idx in range(x['video'].shape[2]):
-                source = x['video'][:, :, 0]
-                driving = x['video'][:, :, frame_idx]
-                kp_driving = kp_detector(driving)
-                out = generator(source, kp_source=kp_source, kp_driving=kp_driving)
+            for i in range(num):
+                out = dict()
+                kp_driving = dict()
+                kp_source = dict()
+                for j in range(5):
+                    if j == 1:
+                        continue
+                    outi_path = out_path + str(cnt) + "_" + str(j) + ".npy"
+                    outi = np.load(outi_path)
+                    if j == 0:
+                        out['mask'] = torch.from_numpy(outi).to(torch.float64)
+                    elif j == 2:
+                        out['occlusion_map'] = torch.from_numpy(outi).to(torch.float64)
+                    elif j == 3:
+                        out['deformed'] = torch.from_numpy(outi).to(torch.float64)
+                    elif j == 4:
+                        out['prediction'] = torch.from_numpy(outi).to(torch.float64)
+
+
+                kp_driving_value_name = kpdv_path + str(cnt) + ".npy"
+                kp_driving_jac_name = kpdj_path + str(cnt) + ".npy"
+                kp_source_value_name = kpsv_path + str(cnt) + ".npy"
+                kp_source_jac_name = kpsj_path + str(cnt) + ".npy"
+                source_name = source_path + str(cnt) + ".npy"
+                driving_name = driving_path + str(cnt) + ".npy"
+
+                kp_driving_value = np.load(kp_driving_value_name)
+                kp_driving_jac = np.load(kp_driving_jac_name)
+                kp_source_value = np.load(kp_source_value_name)
+                kp_source_jac = np.load(kp_source_jac_name)
+                source = np.load(source_name)
+                driving = np.load(driving_name)
+
+                cnt += 1
+
+                kp_driving['value'] = torch.from_numpy(kp_driving_value).to(torch.float64)
+                kp_driving['jacobian'] = torch.from_numpy(kp_driving_jac).to(torch.float64)
+                kp_source['value'] = torch.from_numpy(kp_source_value).to(torch.float64)
+                kp_source['jacobian'] = torch.from_numpy(kp_source_jac).to(torch.float64)
+
                 out['kp_source'] = kp_source
                 out['kp_driving'] = kp_driving
-                del out['sparse_deformed']
+
+                source = torch.from_numpy(source).to(torch.float64)
+                driving = torch.from_numpy(driving).to(torch.float64)
+
                 predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])
 
-                visualization = Visualizer(**config['visualizer_params']).visualize(source=source,
-                                                                                    driving=driving, out=out)
+                visualization = Visualizer(**config['visualizer_params']).visualize(source=source, driving=driving, out=out)
                 visualizations.append(visualization)
 
                 loss_list.append(torch.abs(out['prediction'] - driving).mean().cpu().numpy())
-- 
2.39.0.windows.2

