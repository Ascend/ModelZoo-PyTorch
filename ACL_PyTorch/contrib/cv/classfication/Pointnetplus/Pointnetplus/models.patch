diff --git a/models/pointnet2_cls_ssg.py b/models/pointnet2_cls_ssg.py
index 4e14ba6..80e0626 100644
--- a/models/pointnet2_cls_ssg.py
+++ b/models/pointnet2_cls_ssg.py
@@ -1,15 +1,15 @@
 import torch.nn as nn
 import torch.nn.functional as F
-from pointnet2_utils import PointNetSetAbstraction
+from pointnet2_utils import PointNetSetAbstraction, PointNetSetAbstractionFix
 
 
-class get_model(nn.Module):
-    def __init__(self,num_class,normal_channel=True):
-        super(get_model, self).__init__()
+class get_model_part1(nn.Module):
+    def __init__(self, num_class=40, normal_channel=True):
+        super(get_model_part1, self).__init__()
         in_channel = 6 if normal_channel else 3
         self.normal_channel = normal_channel
-        self.sa1 = PointNetSetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=in_channel, mlp=[64, 64, 128], group_all=False)
-        self.sa2 = PointNetSetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)
+        self.sa1 = PointNetSetAbstractionFix(npoint=512, radius=0.2, nsample=32, in_channel=in_channel, mlp=[64, 64, 128], group_all=False)
+        self.sa2 = PointNetSetAbstractionFix(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)
         self.sa3 = PointNetSetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256 + 3, mlp=[256, 512, 1024], group_all=True)
         self.fc1 = nn.Linear(1024, 512)
         self.bn1 = nn.BatchNorm1d(512)
@@ -19,27 +19,53 @@ class get_model(nn.Module):
         self.drop2 = nn.Dropout(0.4)
         self.fc3 = nn.Linear(256, num_class)
 
-    def forward(self, xyz):
+    def forward(self, xyz, sample_point):
         B, _, _ = xyz.shape
         if self.normal_channel:
             norm = xyz[:, 3:, :]
             xyz = xyz[:, :3, :]
         else:
             norm = None
-        l1_xyz, l1_points = self.sa1(xyz, norm)
-        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)
-        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)
-        x = l3_points.view(B, 1024)
+        l1_xyz, l1_points = self.sa1(xyz, sample_point, norm)
+        return l1_xyz, l1_points
+        # l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)
+        # l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)
+        # x = l3_points.view(B, 1024)
+        # x = self.drop1(F.relu(self.bn1(self.fc1(x))))
+        # x = self.drop2(F.relu(self.bn2(self.fc2(x))))
+        # x = self.fc3(x)
+        # x = F.log_softmax(x, -1)
+        # return x, l3_points
+
+
+class get_model_part2(nn.Module):
+    def __init__(self, num_class=40, normal_channel=True):
+        super(get_model_part2, self).__init__()
+        in_channel = 6 if normal_channel else 3
+        self.normal_channel = normal_channel
+        self.sa1 = PointNetSetAbstractionFix(npoint=512, radius=0.2, nsample=32, in_channel=in_channel, mlp=[64, 64, 128], group_all=False)
+        self.sa2 = PointNetSetAbstractionFix(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)
+        self.sa3 = PointNetSetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256 + 3, mlp=[256, 512, 1024], group_all=True)
+        self.fc1 = nn.Linear(1024, 512)
+        self.bn1 = nn.BatchNorm1d(512)
+        self.drop1 = nn.Dropout(0.4)
+        self.fc2 = nn.Linear(512, 256)
+        self.bn2 = nn.BatchNorm1d(256)
+        self.drop2 = nn.Dropout(0.4)
+        self.fc3 = nn.Linear(256, num_class)
+
+    def forward(self, l1_xyz, sample_point):
+        l2_xyz, l2_points = self.sa2(l1_xyz, sample_point, points=None)
+        l3_xyz, l3_points = self.sa3(l2_xyz, sample_point, l2_points)
+        x = l3_points.view(-1, 1024)
         x = self.drop1(F.relu(self.bn1(self.fc1(x))))
         x = self.drop2(F.relu(self.bn2(self.fc2(x))))
         x = self.fc3(x)
         x = F.log_softmax(x, -1)
 
-
         return x, l3_points
 
 
-
 class get_loss(nn.Module):
     def __init__(self):
         super(get_loss, self).__init__()
diff --git a/models/pointnet2_utils.py b/models/pointnet2_utils.py
index d13986e..55eed61 100644
--- a/models/pointnet2_utils.py
+++ b/models/pointnet2_utils.py
@@ -107,7 +107,7 @@ def query_ball_point(radius, nsample, xyz, new_xyz):
     return group_idx
 
 
-def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):
+def sample_and_group(npoint, radius, nsample, xyz, points, smp_points, returnfps=False):
     """
     Input:
         npoint:
@@ -121,8 +121,8 @@ def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):
     """
     B, N, C = xyz.shape
     S = npoint
-    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]
-    new_xyz = index_points(xyz, fps_idx)
+    # fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]
+    new_xyz = index_points(xyz, smp_points)
     idx = query_ball_point(radius, nsample, xyz, new_xyz)
     grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C]
     grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)
@@ -133,7 +133,7 @@ def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):
     else:
         new_points = grouped_xyz_norm
     if returnfps:
-        return new_xyz, new_points, grouped_xyz, fps_idx
+        return new_xyz, new_points, grouped_xyz, smp_point
     else:
         return new_xyz, new_points
 
@@ -158,6 +158,58 @@ def sample_and_group_all(xyz, points):
     return new_xyz, new_points
 
 
+def sample_and_group_all_fix(xyz, points):
+    """
+    Input:
+        xyz: input points position data, [B, 3, N]
+        points: input points data, [B, D, N]
+    Return:
+        new_xyz: sampled points position data, [B, 3, 1]
+        new_points: sampled points data, [B, 1, N, 3+D]
+    """
+    device = xyz.device
+    B, C, N = xyz.shape
+    new_xyz = torch.zeros(B, C, 1).to(device)
+    grouped_xyz = xyz.view(B, C, N, 1)
+    if points is not None:
+        new_points = torch.cat([grouped_xyz, points.view(B, -1, N, 1)], dim=1)
+    else:
+        new_points = grouped_xyz
+    return new_xyz, new_points
+
+
+class PointNetSetAbstractionFix(nn.Module):
+    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):
+        super(PointNetSetAbstractionFix, self).__init__()
+        self.npoint = npoint
+        self.radius = radius
+        self.nsample = nsample
+        self.mlp_convs = nn.ModuleList()
+        self.mlp_bns = nn.ModuleList()
+        last_channel = in_channel
+        for out_channel in mlp:
+            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))
+            self.mlp_bns.append(nn.BatchNorm2d(out_channel))
+            last_channel = out_channel
+        self.group_all = group_all
+
+    def forward(self, new_xyz, new_points, points=None):
+        """
+        Input:
+            xyz: input points position data, [B, C, N]
+            points: input points data, [B, D, N]
+        Return:
+            new_xyz: sampled points position data, [B, C, S]
+            new_points_concat: sample points feature data, [B, D', S]
+        """
+        for i, conv in enumerate(self.mlp_convs):
+            bn = self.mlp_bns[i]
+            new_points =  F.relu(bn(conv(new_points)))
+
+        new_points = torch.max(new_points, 2)[0]
+        return new_xyz, new_points
+
+
 class PointNetSetAbstraction(nn.Module):
     def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):
         super(PointNetSetAbstraction, self).__init__()
@@ -173,7 +225,7 @@ class PointNetSetAbstraction(nn.Module):
             last_channel = out_channel
         self.group_all = group_all
 
-    def forward(self, xyz, points):
+    def forward(self, xyz, sample_pt, points):
         """
         Input:
             xyz: input points position data, [B, C, N]
@@ -182,23 +234,18 @@ class PointNetSetAbstraction(nn.Module):
             new_xyz: sampled points position data, [B, C, S]
             new_points_concat: sample points feature data, [B, D', S]
         """
-        xyz = xyz.permute(0, 2, 1)
-        if points is not None:
-            points = points.permute(0, 2, 1)
-
         if self.group_all:
-            new_xyz, new_points = sample_and_group_all(xyz, points)
+            new_xyz, new_points = sample_and_group_all_fix(xyz, points)
         else:
-            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)
+            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points, smp_point=sample_pt)
         # new_xyz: sampled points position data, [B, npoint, C]
         # new_points: sampled points data, [B, npoint, nsample, C+D]
-        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint]
+        # new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint]
         for i, conv in enumerate(self.mlp_convs):
             bn = self.mlp_bns[i]
             new_points =  F.relu(bn(conv(new_points)))
 
         new_points = torch.max(new_points, 2)[0]
-        new_xyz = new_xyz.permute(0, 2, 1)
         return new_xyz, new_points
 
 
