diff --git a/configs/m2det512_vgg.py b/configs/m2det512_vgg.py
index 01d21b1..a35fe35 100644
--- a/configs/m2det512_vgg.py
+++ b/configs/m2det512_vgg.py
@@ -1,77 +1,77 @@
-model = dict(
-    type = 'm2det',
-    input_size = 512,
-    init_net = True,
-    pretrained = 'weights/vgg16_reducedfc.pth',
-    m2det_config = dict(
-        backbone = 'vgg16',
-        net_family = 'vgg', # vgg includes ['vgg16','vgg19'], res includes ['resnetxxx','resnextxxx']
-        base_out = [22,34], # [22,34] for vgg, [2,4] or [3,4] for res families
-        planes = 256,
-        num_levels = 8,
-        num_scales = 6,
-        sfam = False,
-        smooth = True,
-        num_classes = 81,
-        ),
-    rgb_means = (104, 117, 123),
-    p = 0.6,
-    anchor_config = dict(
-        step_pattern = [8, 16, 32, 64, 128, 256],
-        size_pattern = [0.06, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05],
-        ),
-    save_eposhs = 10,
-    weights_save = 'weights/'
-    )
-
-train_cfg = dict(
-    cuda = True,
-    warmup = 5,
-    per_batch_size = 16,
-    lr = [0.004, 0.002, 0.0004, 0.00004, 0.000004],
-    gamma = 0.1,
-    end_lr = 1e-6,
-    step_lr = dict(
-        COCO = [90, 110, 130, 150, 160],
-        VOC = [100, 150, 200, 250, 300], # unsolve
-        ),
-    print_epochs = 10,
-    num_workers= 8,
-    )
-
-test_cfg = dict(
-    cuda = True,
-    topk = 0,
-    iou = 0.45,
-    soft_nms = True,
-    score_threshold = 0.1,
-    keep_per_class = 50,
-    save_folder = 'eval'
-    )
-
-loss = dict(overlap_thresh = 0.5,
-            prior_for_matching = True,
-            bkg_label = 0,
-            neg_mining = True,
-            neg_pos = 3,
-            neg_overlap = 0.5,
-            encode_target = False)
-
-optimizer = dict(type='SGD', momentum=0.9, weight_decay=0.0005)
-
-dataset = dict(
-    VOC = dict(
-        train_sets = [('2007', 'trainval'), ('2012', 'trainval')],
-        eval_sets = [('2007', 'test')],
-        ),
-    COCO = dict(
-        train_sets = [('2014', 'train'), ('2014', 'valminusminival')],
-        eval_sets = [('2014', 'minival')],
-        test_sets = [('2015', 'test-dev')],
-        )
-    )
-
-import os
-home = os.path.expanduser("~")
-VOCroot = os.path.join(home,"data/VOCdevkit/")
-COCOroot = os.path.join(home,"data/coco/")
+model = dict(
+    type = 'm2det',
+    input_size = 512,
+    init_net = True,
+    pretrained = 'M2Det/weights/vgg16_reducedfc.pth',
+    m2det_config = dict(
+        backbone = 'vgg16',
+        net_family = 'vgg', # vgg includes ['vgg16','vgg19'], res includes ['resnetxxx','resnextxxx']
+        base_out = [22,34], # [22,34] for vgg, [2,4] or [3,4] for res families
+        planes = 256,
+        num_levels = 8,
+        num_scales = 6,
+        sfam = False,
+        smooth = True,
+        num_classes = 81,
+        ),
+    rgb_means = (104, 117, 123),
+    p = 0.6,
+    anchor_config = dict(
+        step_pattern = [8, 16, 32, 64, 128, 256],
+        size_pattern = [0.06, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05],
+        ),
+    save_eposhs = 10,
+    weights_save = 'weights/'
+    )
+
+train_cfg = dict(
+    cuda = True,
+    warmup = 5,
+    per_batch_size = 16,
+    lr = [0.004, 0.002, 0.0004, 0.00004, 0.000004],
+    gamma = 0.1,
+    end_lr = 1e-6,
+    step_lr = dict(
+        COCO = [90, 110, 130, 150, 160],
+        VOC = [100, 150, 200, 250, 300], # unsolve
+        ),
+    print_epochs = 10,
+    num_workers= 8,
+    )
+
+test_cfg = dict(
+    cuda = True,
+    topk = 0,
+    iou = 0.45,
+    soft_nms = True,
+    score_threshold = 0.1,
+    keep_per_class = 50,
+    save_folder = 'eval'
+    )
+
+loss = dict(overlap_thresh = 0.5,
+            prior_for_matching = True,
+            bkg_label = 0,
+            neg_mining = True,
+            neg_pos = 3,
+            neg_overlap = 0.5,
+            encode_target = False)
+
+optimizer = dict(type='SGD', momentum=0.9, weight_decay=0.0005)
+
+dataset = dict(
+    VOC = dict(
+        train_sets = [('2007', 'trainval'), ('2012', 'trainval')],
+        eval_sets = [('2007', 'test')],
+        ),
+    COCO = dict(
+        train_sets = [('2014', 'train'), ('2014', 'valminusminival')],
+        eval_sets = [('2017', 'val')],
+        test_sets = [('2015', 'test-dev')],
+        )
+    )
+
+import os
+home = os.path.expanduser("~")
+VOCroot = os.path.join(home,"data/VOCdevkit/")
+COCOroot = os.path.join(home,"data/coco/")
diff --git a/data/coco.py b/data/coco.py
index 3784d65..43a62d3 100644
--- a/data/coco.py
+++ b/data/coco.py
@@ -24,9 +24,10 @@ from utils.pycocotools import mask as COCOmask
 
 class COCODetection(data.Dataset):
 
-    def __init__(self, root, image_sets, preproc=None, target_transform=None,
+    def __init__(self, args, image_sets, preproc=None, target_transform=None,
                  dataset_name='COCO'):
-        self.root = root
+        self.COCO_imgs = args.COCO_imgs
+        self.COCO_anns = args.COCO_anns
         self.data_path = os.path.join(os.path.expanduser("~"),'data')
         self.cache_path = os.path.join(self.data_path, 'coco_cache')
         self.image_set = image_sets
@@ -36,7 +37,7 @@ class COCODetection(data.Dataset):
         self.ids = list()
         self.annotations = list()
         self._view_map = {
-            'minival2014' : 'val2014',          # 5k val2014 subset
+            'val2017' : 'val2017',          # 5k val2017 subset
             'valminusminival2014' : 'val2014',  # val2014 \setminus minival2014
             'test-dev2015' : 'test2015',
         }
@@ -57,6 +58,7 @@ class COCODetection(data.Dataset):
             self._class_to_coco_cat_id = dict(zip([c['name'] for c in cats],
                                                   _COCO.getCatIds()))
             indexes = _COCO.getImgIds()
+            indexes = sorted(indexes)
             self.image_indexes = indexes
             self.ids.extend([self.image_path_from_index(data_name, index) for index in indexes ])
             if image_set.find('test') != -1:
@@ -72,10 +74,10 @@ class COCODetection(data.Dataset):
         """
         # Example image path for index=119993:
         #   images/train2014/COCO_train2014_000000119993.jpg
-        file_name = ('COCO_' + name + '_' +
-                     str(index).zfill(12) + '.jpg')
-        image_path = os.path.join(self.root, 'images',
-                              name, file_name)
+        file_name = (str(index).zfill(12) + '.jpg')
+        #image_path = os.path.join(self.root, 'images',
+        #                      name, file_name)
+        image_path = os.path.join(self.COCO_imgs, name, file_name)
         assert os.path.exists(image_path), \
                 'Path does not exist: {}'.format(image_path)
         return image_path
@@ -84,12 +86,14 @@ class COCODetection(data.Dataset):
     def _get_ann_file(self, name):
         prefix = 'instances' if name.find('test') == -1 \
                 else 'image_info'
-        return os.path.join(self.root, 'annotations',
-                        prefix + '_' + name + '.json')
-
+        #return os.path.join(self.root, 'annotations',
+        #                prefix + '_' + name + '.json')
+        return os.path.join(self.COCO_anns, prefix + '_' + name + '.json')
 
     def _load_coco_annotations(self, coco_name, indexes, _COCO):
         cache_file=os.path.join(self.cache_path,coco_name+'_gt_roidb.pkl')
+        if not os.path.exists(self.cache_path):
+            os.makedirs(self.cache_path)
         if os.path.exists(cache_file):
             with open(cache_file, 'rb') as fid:
                 roidb = pickle.load(fid)
@@ -179,7 +183,7 @@ class COCODetection(data.Dataset):
             PIL img
         '''
         img_id = self.ids[index]
-        return cv2.imread(img_id, cv2.IMREAD_COLOR)
+        return cv2.imread(img_id, cv2.IMREAD_COLOR), img_id
 
 
     def pull_tensor(self, index):
@@ -246,7 +250,7 @@ class COCODetection(data.Dataset):
     def _coco_results_one_category(self, boxes, cat_id):
         results = []
         for im_ind, index in enumerate(self.image_indexes):
-            dets = boxes[im_ind].astype(np.float)
+            dets = np.array(boxes[im_ind], dtype=np.float)
             if dets == []:
                 continue
             scores = dets[:, -1]
diff --git a/layers/functions/detection.py b/layers/functions/detection.py
index 841abf9..767c0c4 100644
--- a/layers/functions/detection.py
+++ b/layers/functions/detection.py
@@ -32,13 +32,18 @@ class Detect(Function):
         loc, conf = predictions
 
         loc_data = loc.data
+        #print('loc_data:{}'.format(loc_data.shape))
         conf_data = conf.data
+        #print('conf_data:{}'.format(conf_data.shape))
         prior_data = prior.data
         num = loc_data.size(0)  # batch size
+        #print('num:{}'.format(num))
         self.num_priors = prior_data.size(0)
+        #print('num_priors:{}'.format(self.num_priors))
         self.boxes = torch.zeros(1, self.num_priors, 4)
         self.scores = torch.zeros(1, self.num_priors, self.num_classes)
         if loc_data.is_cuda:
+            print('use cuda')
             self.boxes = self.boxes.cuda()
             self.scores = self.scores.cuda()
 
@@ -47,11 +52,10 @@ class Detect(Function):
             conf_preds = conf_data.unsqueeze(0)
 
         else:
-            conf_preds = conf_data.view(num, num_priors,
+            conf_preds = conf_data.view(num, self.num_priors,
                                         self.num_classes)
             self.boxes.expand_(num, self.num_priors, 4)
             self.scores.expand_(num, self.num_priors, self.num_classes)
-
         # Decode predictions into bboxes.
         for i in range(num):
             decoded_boxes = decode(loc_data[i], prior_data, self.variance)
diff --git a/make.sh b/make.sh
index a8893bc..84af1e2 100644
--- a/make.sh
+++ b/make.sh
@@ -1,7 +1,7 @@
 #!/usr/bin/env bash
 cd ./utils/
 
-CUDA_PATH=/usr/local/cuda/
+#CUDA_PATH=/usr/local/cuda/
 
 python build.py build_ext --inplace
 
diff --git a/utils/build.py b/utils/build.py
index fe33bc1..db29076 100644
--- a/utils/build.py
+++ b/utils/build.py
@@ -56,7 +56,7 @@ def locate_cuda():
     return cudaconfig
 
 
-CUDA = locate_cuda()
+#CUDA = locate_cuda()
 
 # Obtain the numpy include directory.  This logic works across numpy versions.
 try:
@@ -87,6 +87,7 @@ def customize_compiler_for_nvcc(self):
     # based on source extension: we add it.
     def _compile(obj, src, ext, cc_args, extra_postargs, pp_opts):
         print(extra_postargs)
+        '''
         if os.path.splitext(src)[1] == '.cu':
             # use the cuda for .cu files
             self.set_executable('compiler_so', CUDA['nvcc'])
@@ -95,7 +96,8 @@ def customize_compiler_for_nvcc(self):
             postargs = extra_postargs['nvcc']
         else:
             postargs = extra_postargs['gcc']
-
+        '''
+        postargs = extra_postargs['gcc']
         super(obj, src, ext, cc_args, postargs, pp_opts)
         # reset the default compiler_so, which we might have changed for cuda
         self.compiler_so = default_compiler_so
@@ -110,7 +112,7 @@ class custom_build_ext(build_ext):
         customize_compiler_for_nvcc(self.compiler)
         build_ext.build_extensions(self)
 
-
+'''
 ext_modules = [
     Extension(
         "nms.cpu_nms",
@@ -143,7 +145,22 @@ ext_modules = [
             'gcc': ['-Wno-cpp', '-Wno-unused-function', '-std=c99']},
     ),
 ]
-
+'''
+ext_modules = [
+    Extension(
+        "nms.cpu_nms",
+        ["nms/cpu_nms.pyx"],
+        extra_compile_args={'gcc': ["-Wno-cpp", "-Wno-unused-function"]},
+        include_dirs=[numpy_include]
+    ),
+    Extension(
+        'pycocotools._mask',
+        sources=['pycocotools/maskApi.c', 'pycocotools/_mask.pyx'],
+        include_dirs=[numpy_include, 'pycocotools'],
+        extra_compile_args={
+            'gcc': ['-Wno-cpp', '-Wno-unused-function', '-std=c99']},
+    ),
+]
 setup(
     name='mot_utils',
     ext_modules=ext_modules,
diff --git a/utils/core.py b/utils/core.py
index 4da901e..26ba394 100644
--- a/utils/core.py
+++ b/utils/core.py
@@ -84,15 +84,15 @@ def adjust_learning_rate(optimizer, gamma, epoch, step_index, iteration, epoch_s
     return lr
 
 
-def get_dataloader(cfg, dataset, setname='train_sets'):
+def get_dataloader(args, cfg, dataset, setname='train_sets'):
     _preproc = preproc(cfg.model.input_size, cfg.model.rgb_means, cfg.model.p)
     Dataloader_function = {'VOC': VOCDetection, 'COCO':COCODetection}
     _Dataloader_function = Dataloader_function[dataset]
     if setname == 'train_sets':
-        dataset = _Dataloader_function(cfg.COCOroot if dataset == 'COCO' else cfg.VOCroot,
+        dataset = _Dataloader_function(args if dataset == 'COCO' else cfg.VOCroot,
                                    getattr(cfg.dataset, dataset)[setname], _preproc)
     else:
-        dataset = _Dataloader_function(cfg.COCOroot if dataset == 'COCO' else cfg.VOCroot,
+        dataset = _Dataloader_function(args if dataset == 'COCO' else cfg.VOCroot,
                                    getattr(cfg.dataset, dataset)[setname], None)
     return dataset
     
@@ -165,4 +165,34 @@ def nms_process(num_classes, i, scores, boxes, cfg, min_thresh, all_boxes, max_p
                 keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]
                 all_boxes[j][i] = all_boxes[j][i][keep, :]
 
-
+##-自定义logr函数
+def set_train_log():
+
+     date = time.strftime("%m_%d_%H_%M") + '_loss.log'
+     log_path = 'M2Det/logs/'+ date
+     if os.path.exists(log_path):
+         #os.remove(log_path)
+         print('{}路径已存在'.format(log_path))
+     else:
+         os.mknod(log_path)
+     logr = train_log(log_path)
+     return logr
+
+def train_log(filename, verbosity=1, name=None):
+    import logging
+    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}
+    formatter = logging.Formatter(
+        "[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s"
+    )
+    logr = logging.getLogger(name)
+    logr.setLevel(level_dict[verbosity])
+
+    fh = logging.FileHandler(filename, "w")
+    fh.setFormatter(formatter)
+    logr.addHandler(fh)
+    #输出到终端
+    #sh = logging.StreamHandler()
+    #sh.setFormatter(formatter)
+    #logr.addHandler(sh)
+
+    return logr
diff --git a/utils/nms_wrapper.py b/utils/nms_wrapper.py
index 09b1ca7..b65ef70 100644
--- a/utils/nms_wrapper.py
+++ b/utils/nms_wrapper.py
@@ -6,7 +6,7 @@
 # --------------------------------------------------------
 
 from .nms.cpu_nms import cpu_nms, cpu_soft_nms
-from .nms.gpu_nms import gpu_nms
+
 
 
 # def nms(dets, thresh, force_cpu=False):
@@ -25,7 +25,5 @@ def nms(dets, thresh, force_cpu=False):
 
     if dets.shape[0] == 0:
         return []
-    if force_cpu:
-        return cpu_soft_nms(dets, thresh, method = 1)
-        #return cpu_nms(dets, thresh)
-    return gpu_nms(dets, thresh)
+
+    return cpu_soft_nms(dets, thresh, method = 1)
\ No newline at end of file
diff --git a/utils/pycocotools/cocoeval.py b/utils/pycocotools/cocoeval.py
index cd42852..281813f 100644
--- a/utils/pycocotools/cocoeval.py
+++ b/utils/pycocotools/cocoeval.py
@@ -498,8 +498,10 @@ class Params:
         self.imgIds = []
         self.catIds = []
         # np.arange causes trouble.  the data point on arange is slightly larger than the true value
-        self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)
-        self.recThrs = np.linspace(.0, 1.00, np.round((1.00 - .0) / .01) + 1, endpoint=True)
+        #self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)
+        #self.recThrs = np.linspace(.0, 1.00, np.round((1.00 - .0) / .01) + 1, endpoint=True)
+        self.iouThrs = np.linspace(.5, 0.95, 10, endpoint=True)
+        self.recThrs = np.linspace(.0, 1.00, 101, endpoint=True)
         self.maxDets = [1, 10, 100]
         self.areaRng = [[0 ** 2, 1e5 ** 2], [0 ** 2, 32 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]
         self.areaRngLbl = ['all', 'small', 'medium', 'large']
