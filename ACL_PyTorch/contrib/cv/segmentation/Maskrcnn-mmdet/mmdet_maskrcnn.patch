diff --git a/mmdetection-2.8.0/mmdet/core/post_processing/bbox_nms.py b/mmdetection-2.8.0-acl/mmdet/core/post_processing/bbox_nms.py
index 463fe2e..e0afee2 100644
--- a/mmdetection-2.8.0/mmdet/core/post_processing/bbox_nms.py
+++ b/mmdetection-2.8.0-acl/mmdet/core/post_processing/bbox_nms.py
@@ -3,6 +3,56 @@ from mmcv.ops.nms import batched_nms
 
 from mmdet.core.bbox.iou_calculators import bbox_overlaps
 
+class BatchNMSOp(torch.autograd.Function):
+    @staticmethod
+    def forward(ctx, bboxes, scores, score_threshold, iou_threshold, max_size_per_class, max_total_size):
+        """
+        boxes (torch.Tensor): boxes in shape (batch, N, C, 4).
+        scores (torch.Tensor): scores in shape (batch, N, C).
+        return:
+            nmsed_boxes: (1, N, 4)
+            nmsed_scores: (1, N)
+            nmsed_classes: (1, N)
+            nmsed_num: (1,)
+        """
+
+        # Phony implementation for onnx export
+        nmsed_boxes = bboxes[:, :max_total_size, 0, :]
+        nmsed_scores = scores[:, :max_total_size, 0]
+        nmsed_classes = torch.arange(max_total_size, dtype=torch.long)
+        nmsed_num = torch.Tensor([max_total_size])
+
+        return nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num
+
+    @staticmethod
+    def symbolic(g, bboxes, scores, score_thr, iou_thr, max_size_p_class, max_t_size):
+        nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num = g.op('BatchMultiClassNMS',
+            bboxes, scores, score_threshold_f=score_thr, iou_threshold_f=iou_thr,
+            max_size_per_class_i=max_size_p_class, max_total_size_i=max_t_size, outputs=4)
+        return nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num
+
+def batch_nms_op(bboxed, scores, score_threshold, iou_threshold, max_size_per_class, max_total_size):
+    """
+    boxes (torch.Tensor): boxes in shape (N, 4).
+    SCORES (torch.Tensor): scores in shape (N, ).
+    """
+
+    if bboxes.dtype == torch.float32:
+        bboxes = bboxes.reshape(1, bboxes.shape[0].numpy(), -1, 4).half()
+        scores = scores.reshape(1, scores.shape[0].numpy(), -1).half()
+    else:
+        bboxes = bboxes.reshape(1, bboxes.shape[0].numpy(), -1, 4)
+        scores = scores.reshape(1, scores.shape[0].numpy(), -1)
+    
+    nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num = BatchNMSOp.apply(bboxes, scores,
+        score_threshold, iou_threshold, max_size_per_class, max_total_size)
+    nmsed_boxes = nmsed_boxes.float()
+    nmsed_scores = nmsed_scores.float()
+    nmsed_classes = nmsed_classes.long()
+    dets = torch.cat((nmsed_boxes.reshape(max_total_size,4), nmsed_scores.reshape(max_total_size, 1)), -1)
+    labels = nmsed_classes.reshape(max_total_size, )
+    
+    return dets, labels
 
 def multiclass_nms(multi_bboxes,
                    multi_scores,
@@ -36,13 +86,25 @@ def multiclass_nms(multi_bboxes,
     if multi_bboxes.shape[1] > 4:
         bboxes = multi_bboxes.view(multi_scores.size(0), -1, 4)
     else:
-        bboxes = multi_bboxes[:, None].expand(
-            multi_scores.size(0), num_classes, 4)
+        # export expand operator to onnx
+        if torch.onnx.is_in_onnx_export:
+            bbox_shape_tensor = torch.ones(multi_scores.size(0), num_classes, 4)
+            bboxes - multi_bboxes[:, None].expand_as(bbox_shape_tensor)
+        else:
+            bboxes = multi_bboxes[:, None].expand(
+                multi_scores.size(0), num_classes, 4)
+
 
     scores = multi_scores[:, :-1]
     if score_factors is not None:
         scores = scores * score_factors[:, None]
 
+    # npu
+    if torch.onnx.is_in_onnx_export():
+        dets, labels = batch_nms_op(bboxes, score, score_thr, nms_cfg.get("iou_threshold"), max_num, max_num)
+        return dets, labels
+    
+    # cpu and gpu
     labels = torch.arange(num_classes, dtype=torch.long)
     labels = labels.view(1, -1).expand_as(scores)
 
diff --git a/mmdetection-2.8.0/mmdet/models/dense_heads/rpn_head.py b/mmdetection-2.8.0-acl/mmdet/models/dense_heads/rpn_head.py
index f565d1a..70392a8 100644
--- a/mmdetection-2.8.0/mmdet/models/dense_heads/rpn_head.py
+++ b/mmdetection-2.8.0-acl/mmdet/models/dense_heads/rpn_head.py
@@ -8,6 +8,56 @@ from ..builder import HEADS
 from .anchor_head import AnchorHead
 from .rpn_test_mixin import RPNTestMixin
 
+class BatchNMSOp(torch.autograd.Function):
+    @staticmethod
+    def forward(ctx, bboxes, scores, score_threshold, iou_threshold, max_size_per_class, max_total_size):
+        """
+        boxes (torch.Tensor): boxes in shape (batch, N, C, 4).
+        scores (torch.Tensor): scores in shape (batch, N, C).
+        return:
+            nmsed_boxes: (1, N, 4)
+            nmsed_scores: (1, N)
+            nmsed_classes: (1, N)
+            nmsed_num: (1,)
+        """
+
+        # Phony implementation for onnx export
+        nmsed_boxes = bboxes[:, :max_total_size, 0, :]
+        nmsed_scores = scores[:, :max_total_size, 0]
+        nmsed_classes = torch.arange(max_total_size, dtype=torch.long)
+        nmsed_num = torch.Tensor([max_total_size])
+
+        return nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num
+
+    @staticmethod
+    def symbolic(g, bboxes, scores, score_thr, iou_thr, max_size_p_class, max_t_size):
+        nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num = g.op('BatchMultiClassNMS',
+            bboxes, scores, score_threshold_f=score_thr, iou_threshold_f=iou_thr,
+            max_size_per_class_i=max_size_p_class, max_total_size_i=max_t_size, outputs=4)
+        return nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num
+
+def batch_nms_op(bboxed, scores, score_threshold, iou_threshold, max_size_per_class, max_total_size):
+    """
+    boxes (torch.Tensor): boxes in shape (N, 4).
+    SCORES (torch.Tensor): scores in shape (N, ).
+    """
+
+    if bboxes.dtype == torch.float32:
+        bboxes = bboxes.reshape(1, bboxes.shape[0].numpy(), -1, 4).half()
+        scores = scores.reshape(1, scores.shape[0].numpy(), -1).half()
+    else:
+        bboxes = bboxes.reshape(1, bboxes.shape[0].numpy(), -1, 4)
+        scores = scores.reshape(1, scores.shape[0].numpy(), -1)
+    
+    nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_num = BatchNMSOp.apply(bboxes, scores,
+        score_threshold, iou_threshold, max_size_per_class, max_total_size)
+    nmsed_boxes = nmsed_boxes.float()
+    nmsed_scores = nmsed_scores.float()
+    nmsed_classes = nmsed_classes.long()
+    dets = torch.cat((nmsed_boxes.reshape(max_total_size,4), nmsed_scores.reshape(max_total_size, 1)), -1)
+    labels = nmsed_classes.reshape(max_total_size, )
+
+    return dets, labels
 
 @HEADS.register_module()
 class RPNHead(RPNTestMixin, AnchorHead):
@@ -132,9 +182,15 @@ class RPNHead(RPNTestMixin, AnchorHead):
             if cfg.nms_pre > 0 and scores.shape[0] > cfg.nms_pre:
                 # sort is faster than topk
                 # _, topk_inds = scores.topk(cfg.nms_pre)
-                ranked_scores, rank_inds = scores.sort(descending=True)
-                topk_inds = rank_inds[:cfg.nms_pre]
-                scores = ranked_scores[:cfg.nms_pre]
+                
+                # better use topk to sort for onnx
+                if torch.onnx.is_in_onnx_export():
+                    scores, topk_inds = torch.topk(scores, cfg.nms_pre)
+                else:
+                    ranked_scores, rank_inds = scores.sort(descending=True)
+                    topk_inds = rank_inds[:cfg.nms_pre]
+                    scores = ranked_scores[:cfg.nms_pre]
+                
                 rpn_bbox_pred = rpn_bbox_pred[topk_inds, :]
                 anchors = anchors[topk_inds, :]
             mlvl_scores.append(scores)
@@ -164,5 +220,11 @@ class RPNHead(RPNTestMixin, AnchorHead):
 
         # TODO: remove the hard coded nms type
         nms_cfg = dict(type='nms', iou_threshold=cfg.nms_thr)
-        dets, keep = batched_nms(proposals, scores, ids, nms_cfg)
-        return dets[:cfg.nms_post]
+        # npu return
+        if torch.onnx.is_in_onnx_export():
+            dets, labels = batch_nms_op(proposals, scores, 0.0, nms_cfg("iou_threshold"), cfg.nms_post, cfg.nms_post)
+            return dets
+        # cpu and gpu return
+        else:
+            dets, keep = batched_nms(proposals, scores, ids, nms_cfg)
+            return dets[:cfg.nms_post]
diff --git a/mmdetection-2.8.0/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py b/mmdetection-2.8.0/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py
deleted file mode 100644
index 0cba3cd..0000000
--- a/mmdetection-2.8.0/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py
+++ /dev/null
@@ -1,328 +0,0 @@
-import numpy as np
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from mmcv.cnn import Conv2d, ConvModule, build_upsample_layer
-from mmcv.ops.carafe import CARAFEPack
-from mmcv.runner import auto_fp16, force_fp32
-from torch.nn.modules.utils import _pair
-
-from mmdet.core import mask_target
-from mmdet.models.builder import HEADS, build_loss
-
-BYTES_PER_FLOAT = 4
-# TODO: This memory limit may be too much or too little. It would be better to
-# determine it based on available resources.
-GPU_MEM_LIMIT = 1024**3  # 1 GB memory limit
-
-
-@HEADS.register_module()
-class FCNMaskHead(nn.Module):
-
-    def __init__(self,
-                 num_convs=4,
-                 roi_feat_size=14,
-                 in_channels=256,
-                 conv_kernel_size=3,
-                 conv_out_channels=256,
-                 num_classes=80,
-                 class_agnostic=False,
-                 upsample_cfg=dict(type='deconv', scale_factor=2),
-                 conv_cfg=None,
-                 norm_cfg=None,
-                 loss_mask=dict(
-                     type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)):
-        super(FCNMaskHead, self).__init__()
-        self.upsample_cfg = upsample_cfg.copy()
-        if self.upsample_cfg['type'] not in [
-                None, 'deconv', 'nearest', 'bilinear', 'carafe'
-        ]:
-            raise ValueError(
-                f'Invalid upsample method {self.upsample_cfg["type"]}, '
-                'accepted methods are "deconv", "nearest", "bilinear", '
-                '"carafe"')
-        self.num_convs = num_convs
-        # WARN: roi_feat_size is reserved and not used
-        self.roi_feat_size = _pair(roi_feat_size)
-        self.in_channels = in_channels
-        self.conv_kernel_size = conv_kernel_size
-        self.conv_out_channels = conv_out_channels
-        self.upsample_method = self.upsample_cfg.get('type')
-        self.scale_factor = self.upsample_cfg.pop('scale_factor', None)
-        self.num_classes = num_classes
-        self.class_agnostic = class_agnostic
-        self.conv_cfg = conv_cfg
-        self.norm_cfg = norm_cfg
-        self.fp16_enabled = False
-        self.loss_mask = build_loss(loss_mask)
-
-        self.convs = nn.ModuleList()
-        for i in range(self.num_convs):
-            in_channels = (
-                self.in_channels if i == 0 else self.conv_out_channels)
-            padding = (self.conv_kernel_size - 1) // 2
-            self.convs.append(
-                ConvModule(
-                    in_channels,
-                    self.conv_out_channels,
-                    self.conv_kernel_size,
-                    padding=padding,
-                    conv_cfg=conv_cfg,
-                    norm_cfg=norm_cfg))
-        upsample_in_channels = (
-            self.conv_out_channels if self.num_convs > 0 else in_channels)
-        upsample_cfg_ = self.upsample_cfg.copy()
-        if self.upsample_method is None:
-            self.upsample = None
-        elif self.upsample_method == 'deconv':
-            upsample_cfg_.update(
-                in_channels=upsample_in_channels,
-                out_channels=self.conv_out_channels,
-                kernel_size=self.scale_factor,
-                stride=self.scale_factor)
-            self.upsample = build_upsample_layer(upsample_cfg_)
-        elif self.upsample_method == 'carafe':
-            upsample_cfg_.update(
-                channels=upsample_in_channels, scale_factor=self.scale_factor)
-            self.upsample = build_upsample_layer(upsample_cfg_)
-        else:
-            # suppress warnings
-            align_corners = (None
-                             if self.upsample_method == 'nearest' else False)
-            upsample_cfg_.update(
-                scale_factor=self.scale_factor,
-                mode=self.upsample_method,
-                align_corners=align_corners)
-            self.upsample = build_upsample_layer(upsample_cfg_)
-
-        out_channels = 1 if self.class_agnostic else self.num_classes
-        logits_in_channel = (
-            self.conv_out_channels
-            if self.upsample_method == 'deconv' else upsample_in_channels)
-        self.conv_logits = Conv2d(logits_in_channel, out_channels, 1)
-        self.relu = nn.ReLU(inplace=True)
-        self.debug_imgs = None
-
-    def init_weights(self):
-        for m in [self.upsample, self.conv_logits]:
-            if m is None:
-                continue
-            elif isinstance(m, CARAFEPack):
-                m.init_weights()
-            else:
-                nn.init.kaiming_normal_(
-                    m.weight, mode='fan_out', nonlinearity='relu')
-                nn.init.constant_(m.bias, 0)
-
-    @auto_fp16()
-    def forward(self, x):
-        for conv in self.convs:
-            x = conv(x)
-        if self.upsample is not None:
-            x = self.upsample(x)
-            if self.upsample_method == 'deconv':
-                x = self.relu(x)
-        mask_pred = self.conv_logits(x)
-        return mask_pred
-
-    def get_targets(self, sampling_results, gt_masks, rcnn_train_cfg):
-        pos_proposals = [res.pos_bboxes for res in sampling_results]
-        pos_assigned_gt_inds = [
-            res.pos_assigned_gt_inds for res in sampling_results
-        ]
-        mask_targets = mask_target(pos_proposals, pos_assigned_gt_inds,
-                                   gt_masks, rcnn_train_cfg)
-        return mask_targets
-
-    @force_fp32(apply_to=('mask_pred', ))
-    def loss(self, mask_pred, mask_targets, labels):
-        loss = dict()
-        if mask_pred.size(0) == 0:
-            loss_mask = mask_pred.sum()
-        else:
-            if self.class_agnostic:
-                loss_mask = self.loss_mask(mask_pred, mask_targets,
-                                           torch.zeros_like(labels))
-            else:
-                loss_mask = self.loss_mask(mask_pred, mask_targets, labels)
-        loss['loss_mask'] = loss_mask
-        return loss
-
-    def get_seg_masks(self, mask_pred, det_bboxes, det_labels, rcnn_test_cfg,
-                      ori_shape, scale_factor, rescale):
-        """Get segmentation masks from mask_pred and bboxes.
-
-        Args:
-            mask_pred (Tensor or ndarray): shape (n, #class, h, w).
-                For single-scale testing, mask_pred is the direct output of
-                model, whose type is Tensor, while for multi-scale testing,
-                it will be converted to numpy array outside of this method.
-            det_bboxes (Tensor): shape (n, 4/5)
-            det_labels (Tensor): shape (n, )
-            img_shape (Tensor): shape (3, )
-            rcnn_test_cfg (dict): rcnn testing config
-            ori_shape: original image size
-
-        Returns:
-            list[list]: encoded masks
-        """
-        if isinstance(mask_pred, torch.Tensor):
-            mask_pred = mask_pred.sigmoid()
-        else:
-            mask_pred = det_bboxes.new_tensor(mask_pred)
-
-        device = mask_pred.device
-        cls_segms = [[] for _ in range(self.num_classes)
-                     ]  # BG is not included in num_classes
-        bboxes = det_bboxes[:, :4]
-        labels = det_labels
-
-        if rescale:
-            img_h, img_w = ori_shape[:2]
-        else:
-            if isinstance(scale_factor, float):
-                img_h = np.round(ori_shape[0] * scale_factor).astype(np.int32)
-                img_w = np.round(ori_shape[1] * scale_factor).astype(np.int32)
-            else:
-                w_scale, h_scale = scale_factor[0], scale_factor[1]
-                img_h = np.round(ori_shape[0] * h_scale.item()).astype(
-                    np.int32)
-                img_w = np.round(ori_shape[1] * w_scale.item()).astype(
-                    np.int32)
-            scale_factor = 1.0
-
-        if not isinstance(scale_factor, (float, torch.Tensor)):
-            scale_factor = bboxes.new_tensor(scale_factor)
-        bboxes = bboxes / scale_factor
-
-        if torch.onnx.is_in_onnx_export():
-            # TODO: Remove after F.grid_sample is supported.
-            from torchvision.models.detection.roi_heads \
-                import paste_masks_in_image
-            masks = paste_masks_in_image(mask_pred, bboxes, ori_shape[:2])
-            thr = rcnn_test_cfg.get('mask_thr_binary', 0)
-            if thr > 0:
-                masks = masks >= thr
-            return masks
-
-        N = len(mask_pred)
-        # The actual implementation split the input into chunks,
-        # and paste them chunk by chunk.
-        if device.type == 'cpu':
-            # CPU is most efficient when they are pasted one by one with
-            # skip_empty=True, so that it performs minimal number of
-            # operations.
-            num_chunks = N
-        else:
-            # GPU benefits from parallelism for larger chunks,
-            # but may have memory issue
-            num_chunks = int(
-                np.ceil(N * img_h * img_w * BYTES_PER_FLOAT / GPU_MEM_LIMIT))
-            assert (num_chunks <=
-                    N), 'Default GPU_MEM_LIMIT is too small; try increasing it'
-        chunks = torch.chunk(torch.arange(N, device=device), num_chunks)
-
-        threshold = rcnn_test_cfg.mask_thr_binary
-        im_mask = torch.zeros(
-            N,
-            img_h,
-            img_w,
-            device=device,
-            dtype=torch.bool if threshold >= 0 else torch.uint8)
-
-        if not self.class_agnostic:
-            mask_pred = mask_pred[range(N), labels][:, None]
-
-        for inds in chunks:
-            masks_chunk, spatial_inds = _do_paste_mask(
-                mask_pred[inds],
-                bboxes[inds],
-                img_h,
-                img_w,
-                skip_empty=device.type == 'cpu')
-
-            if threshold >= 0:
-                masks_chunk = (masks_chunk >= threshold).to(dtype=torch.bool)
-            else:
-                # for visualization and debugging
-                masks_chunk = (masks_chunk * 255).to(dtype=torch.uint8)
-
-            im_mask[(inds, ) + spatial_inds] = masks_chunk
-
-        for i in range(N):
-            cls_segms[labels[i]].append(im_mask[i].detach().cpu().numpy())
-        return cls_segms
-
-
-def _do_paste_mask(masks, boxes, img_h, img_w, skip_empty=True):
-    """Paste instance masks acoording to boxes.
-
-    This implementation is modified from
-    https://github.com/facebookresearch/detectron2/
-
-    Args:
-        masks (Tensor): N, 1, H, W
-        boxes (Tensor): N, 4
-        img_h (int): Height of the image to be pasted.
-        img_w (int): Width of the image to be pasted.
-        skip_empty (bool): Only paste masks within the region that
-            tightly bound all boxes, and returns the results this region only.
-            An important optimization for CPU.
-
-    Returns:
-        tuple: (Tensor, tuple). The first item is mask tensor, the second one
-            is the slice object.
-        If skip_empty == False, the whole image will be pasted. It will
-            return a mask of shape (N, img_h, img_w) and an empty tuple.
-        If skip_empty == True, only area around the mask will be pasted.
-            A mask of shape (N, h', w') and its start and end coordinates
-            in the original image will be returned.
-    """
-    # On GPU, paste all masks together (up to chunk size)
-    # by using the entire image to sample the masks
-    # Compared to pasting them one by one,
-    # this has more operations but is faster on COCO-scale dataset.
-    device = masks.device
-    if skip_empty:
-        x0_int, y0_int = torch.clamp(
-            boxes.min(dim=0).values.floor()[:2] - 1,
-            min=0).to(dtype=torch.int32)
-        x1_int = torch.clamp(
-            boxes[:, 2].max().ceil() + 1, max=img_w).to(dtype=torch.int32)
-        y1_int = torch.clamp(
-            boxes[:, 3].max().ceil() + 1, max=img_h).to(dtype=torch.int32)
-    else:
-        x0_int, y0_int = 0, 0
-        x1_int, y1_int = img_w, img_h
-    x0, y0, x1, y1 = torch.split(boxes, 1, dim=1)  # each is Nx1
-
-    N = masks.shape[0]
-
-    img_y = torch.arange(
-        y0_int, y1_int, device=device, dtype=torch.float32) + 0.5
-    img_x = torch.arange(
-        x0_int, x1_int, device=device, dtype=torch.float32) + 0.5
-    img_y = (img_y - y0) / (y1 - y0) * 2 - 1
-    img_x = (img_x - x0) / (x1 - x0) * 2 - 1
-    # img_x, img_y have shapes (N, w), (N, h)
-    if torch.isinf(img_x).any():
-        inds = torch.where(torch.isinf(img_x))
-        img_x[inds] = 0
-    if torch.isinf(img_y).any():
-        inds = torch.where(torch.isinf(img_y))
-        img_y[inds] = 0
-
-    gx = img_x[:, None, :].expand(N, img_y.size(1), img_x.size(1))
-    gy = img_y[:, :, None].expand(N, img_y.size(1), img_x.size(1))
-    grid = torch.stack([gx, gy], dim=3)
-
-    if torch.onnx.is_in_onnx_export():
-        raise RuntimeError(
-            'Exporting F.grid_sample from Pytorch to ONNX is not supported.')
-    img_masks = F.grid_sample(
-        masks.to(dtype=torch.float32), grid, align_corners=False)
-
-    if skip_empty:
-        return img_masks[:, 0], (slice(y0_int, y1_int), slice(x0_int, x1_int))
-    else:
-        return img_masks[:, 0], ()
diff --git a/mmdetection-2.8.0/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py b/mmdetection-2.8.0-acl/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py
index c0eebc4..b785847 100644
--- a/mmdetection-2.8.0/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py
+++ b/mmdetection-2.8.0-acl/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py
@@ -4,6 +4,32 @@ from mmcv.runner import force_fp32
 from mmdet.models.builder import ROI_EXTRACTORS
 from .base_roi_extractor import BaseRoIExtractor
 
+import torch.onnx.symbolic_helper as sym_help
+
+class RoiExtractor(torch.autograd.Function):
+    @staticmethod
+    def forward(self, f0, f1, f2, f3, rois, aligned=1, finest_scale=56, pooled_height=7, pooled_width=7,
+        pool_mode='avg', roi_scale_factor=0, sample_num=0, spatial_scale=[0.25, 0.125, 0.0625, 0.03125]):
+        """
+        feats (torch.Tensor): feats in shape (batch, 256, H, W).
+        rois (torch.Tensor): rois in shape(k, 5).
+        return :
+            roi_feats (torch.Tensor): (k, 256, pooled_height, pooled_width)
+        """
+
+        # phony implementation for shape inference
+        k = rois.size()[0]
+        roi_feats = torch.ones(k, 256, pooled_height, pooled_width)
+        return roi_feats
+    
+    @staticmethod
+    def symbolic(g, f0, f1, f2, f3, rois, aligned=1, finest_scale=56, pooled_height=7, pooled_width=7):
+        # TODO: support tensor list type for feats
+        # f_tensors = sym_help._unpack_list(feats)
+        roi_feats = g.op('RoiExtractor', f0, f1, f2, f3, rois, aligned=1, finest_scale=56, pooled_height_i=pooled_height, pooled_width_i=pooled_width,
+            pool_mode_s='avg', roi_scale_factor_i=0, sample_num_i=0, spatial_scale_f=[0.25, 0.125, 0.0625, 0.03125], outputs=1)
+        
+        return roi_feats
 
 @ROI_EXTRACTORS.register_module()
 class SingleRoIExtractor(BaseRoIExtractor):
@@ -52,6 +78,13 @@ class SingleRoIExtractor(BaseRoIExtractor):
 
     @force_fp32(apply_to=('feats', ), out_fp16=True)
     def forward(self, feats, rois, roi_scale_factor=None):
+        # onnx export
+        if torch.onnx.is_in_onnx_export():
+            out_size = self.roi_layers[0].output_size
+            roi_feats = RoiExtractor.apply(feats[0], feats[1], feats[2], feats[3], rois, 1, 56, out_size[0], out_size[1])
+            #roi_feats = RoiExtractor.apply(list(feats), rois)
+            return roi_feats
+
         """Forward function."""
         out_size = self.roi_layers[0].output_size
         num_levels = len(feats)
